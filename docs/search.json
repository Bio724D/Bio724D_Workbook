[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Bio724D",
    "section": "",
    "text": "Preface\nThis book was designed for a Biology 724D: XXXX, a graduate level course offered in the Department of Biology at Duke University."
  },
  {
    "objectID": "Computing_basics/local-computing.html#mac-os",
    "href": "Computing_basics/local-computing.html#mac-os",
    "title": "1  Local computing",
    "section": "1.1 Mac OS",
    "text": "1.1 Mac OS\n\nRoot = /\nOther disks (USB, etc.) mounted under /Volumes\nUser directories under /Users; your home directory at /Users/yourusername\nSystem wide applications under /Applications; users can also install applications under /Users/username/Applicatons\nUser specific config files under /Users/username/Library (hidden by default)\nUnix related executables under /bin, /sbin, etc.\nPATH is an environment variable, settable from command line or ~/.profile"
  },
  {
    "objectID": "Computing_basics/local-computing.html#windows-1011",
    "href": "Computing_basics/local-computing.html#windows-1011",
    "title": "1  Local computing",
    "section": "1.2 Windows 10/11",
    "text": "1.2 Windows 10/11\n\nRoot = C:\\\nOther disks mounted as D:\\, E:, etc.\nUser directories under C:\\Users; your home directory at C:\\Users\\yourusername\nSystem wide applications under c:\\Program Files (64 bit) and C:\\Program Files (x86) (32 bit)\nPath variable settable from “System Properties” dialog"
  },
  {
    "objectID": "Computing_basics/local-computing.html#both",
    "href": "Computing_basics/local-computing.html#both",
    "title": "1  Local computing",
    "section": "1.3 Both",
    "text": "1.3 Both\n\nStandard shortcuts like “Desktop”, “Documents”, and “Downloads” are usually subdirectories of your home directory\nHidden files and directories can be viewed by setting appropriate options in Finder / Explorer"
  },
  {
    "objectID": "Computing_basics/local-computing.html#recommendations-for-file-naming-schemes",
    "href": "Computing_basics/local-computing.html#recommendations-for-file-naming-schemes",
    "title": "1  Local computing",
    "section": "1.4 Recommendations for file naming schemes",
    "text": "1.4 Recommendations for file naming schemes\n\nAvoid spaces (or other non-printing characters) and punctuation other than dashes, underscores, and periods in file names\nFile names that include dates should preferably follow the ISO-8601 formatting standard, which has the form “YYYY-MM-DD”. For example, an experiment done of Jan 12, 2022 should be named something like “2022-01-12-Expt01.csv”.\n\nThe advantage of this is it makes it easy to sort and search by date\n\nTry and be consistent in your naming schemes. I promise this will make your life (and/or that of your collaborators) easier at some point in your research career!\nSee further recommendations from Iowa Stat University’s Open Research Data Repository"
  },
  {
    "objectID": "Computing_basics/local-computing.html#terminology",
    "href": "Computing_basics/local-computing.html#terminology",
    "title": "1  Local computing",
    "section": "1.5 Terminology",
    "text": "1.5 Terminology\n\nA “terminal” is a text input/output environment for interacting with your computer. A terminal used to be a physical device attached to a computer. Strictly speaking, these days we run “terminal emulators” – graphical programs that emulate terminals.\nA “shell” is a program that runs in a terminal that processes and interprets the command you type. You can run different shells in the same terminal."
  },
  {
    "objectID": "Computing_basics/local-computing.html#mac-os-1",
    "href": "Computing_basics/local-computing.html#mac-os-1",
    "title": "1  Local computing",
    "section": "1.6 Mac OS",
    "text": "1.6 Mac OS\n\nTerminal accessed by running “Terminal” program (in the “Applications/Utilities” folder)\nDefault shell is zsh; but bash also included by default (invoke at command line by typing bash)"
  },
  {
    "objectID": "Computing_basics/local-computing.html#windows",
    "href": "Computing_basics/local-computing.html#windows",
    "title": "1  Local computing",
    "section": "1.7 Windows",
    "text": "1.7 Windows\n\nDefault terminal is “Command Prompt” but new “Windows Terminal” is better choice\nSeveral options for shell but I recommend “PowerShell”"
  },
  {
    "objectID": "Computing_basics/local-computing.html#commands-for-navigating-the-file-system-on-unix-based-systems",
    "href": "Computing_basics/local-computing.html#commands-for-navigating-the-file-system-on-unix-based-systems",
    "title": "1  Local computing",
    "section": "1.8 Commands for navigating the file system on Unix based systems",
    "text": "1.8 Commands for navigating the file system on Unix based systems\nNOTE: The following commands also work in Windows PowerShell\n\npwd – prints name of your “working” directory (i.e. the directory you’re currently in)\nls – lists the contents of the working directory\ncd – change directory\n\ncd Downloads\ncd ~ (move to your home directory)\n\nmkdir – make a new directory\n\nmkdir foo_dir\nmkdir bar_dir\n\nrmdir – remove a directory (must be empty)\n\nrmdir bar_dir\n\n\nrm – remove a file\n\nrm bar.txt\n\ncp – copy a file\n\ncp foo.txt foo_copy.txt\n\nmv – move a file or directory\n\nmv foo.txt baz.txt\nmv foo_dir foo.dir\n\ncat – write the contents of a file to the terminal:\n\ncat foo.txt\n\nmore – a pager program. View the contents of a file, one page at a time. Type <space> to advance pages, q to quit.\n\nSide note: Why is it common to use names like foo, bar, and baz in examples? See https://en.wikipedia.org/wiki/Foobar"
  },
  {
    "objectID": "Computing_basics/local-computing.html#shortcuts-for-working-with-the-file-system",
    "href": "Computing_basics/local-computing.html#shortcuts-for-working-with-the-file-system",
    "title": "1  Local computing",
    "section": "1.9 Shortcuts for working with the file system",
    "text": "1.9 Shortcuts for working with the file system\n\n~ – refers to the users home directory.\n\ncd ~ = change to my home directory\nls ~/*.txt = list all files ending with the prefix .txt in your home directory\n\n. – the current directory\n\ncd ./tmp = move to the directory called tmp that is located in the directory the cd command is executed from.\n\n\n.. – the directory above the current directory (if it exists)\n\ncd .. = move up one level in the directory hierarchy. For example if pwd is /home/jsmith then cd .. moves you to /home\n\n/ – the root directory of the file system\ncd /data = move to the data directory that is the subdirectory of the root\nls / = list all files and directories in the root directory"
  },
  {
    "objectID": "Computing_basics/remote-computing.html#moving-files-tofrom-your-vm",
    "href": "Computing_basics/remote-computing.html#moving-files-tofrom-your-vm",
    "title": "2  Remote computing",
    "section": "2.1 Moving files to/from your VM",
    "text": "2.1 Moving files to/from your VM\n\n2.1.1 Using Cyberduck (or another SFTP client)\nCyberduck provides a graphical interface for moving files back and forth to/from a remote machine. We’ll demonstrate how to use Cyberduck in class.\n\n\n2.1.2 Using the command line\n\nscp – secure copy. Command line tool to copy files to or from a remote machine via SSH.\n\nMove a local file (foo.txt) to your virtual machine:\n\nscp foo.txt netid@hostname:~\n\nMove a remote file (~/data/bar.txt) to your local machine (~/bio724/data):\n\nscp netid@hostname:~/data/bar.txt ~/bio724/data (saves bar.txt under the local directory ~/bio724/data assuming that directory already exists)\n\n\nwget – a command line program for downloading files from the web. You would typically use this to download files from a URL to a remote machine.\nTo illustrate the use of wget, we’ll download a file of interest from the NIH National Center for Biotechnology Information (NCBI), which hosts databases like Genbank, SRA, Pubmed, etc.\n\nIn your web browser, navigate to the NCBI SARS-CoV-2 Resources website. About half-way down the page are a set of blue buttons linking to information about the SARS-CoV-2 Genome Reference Sequence (NC_045512).\nRight click the “Download Annotation” button and copy the URL link and then use wget to download the genome annotation file to your VM.\nwget https://ftp.ncbi.nlm.nih.gov/genomes/all/GCF/009/858/895/GCF_009858895.2_ASM985889v3/GCF_009858895.2_ASM985889v3_genomic.gff.gz\nThe .gz prefix indicates that this is a compressed file; compressed using a tool called gzip. To uncompress this file we can use the gunzip command as follows:\ngunzip GCF_009858895.2_ASM985889v3_genomic.gff.gz\nThis will create the uncompressed file named GCF_009858895.2_ASM985889v3_genomic.gff.\nLet’s create a directory for genome annotation files and move our file there:\nmkdir ~/genome_annotations\nmv GCF_009858895.2_ASM985889v3_genomic.gff ~/genome_annotations/\nGFF files are a commonly used format for genome annotations. This is a simple tab-delimited file format with nine columns. A full specification of the GFF format is provided here: https://github.com/The-Sequence-Ontology/Specifications/blob/master/gff3.md"
  },
  {
    "objectID": "R/R-getting-started.html#what-is-r",
    "href": "R/R-getting-started.html#what-is-r",
    "title": "3  Getting Started with R",
    "section": "3.1 What is R?",
    "text": "3.1 What is R?\nR is a statistical computing environment and programming language. It is free, open source, and has a large and active community of developers and users. There are many different R packages (libraries) available for conducting out a wide variety of different analyses, for everything from genome sequence data to geospatial information."
  },
  {
    "objectID": "R/R-getting-started.html#what-is-rstudio",
    "href": "R/R-getting-started.html#what-is-rstudio",
    "title": "3  Getting Started with R",
    "section": "3.2 What is RStudio?",
    "text": "3.2 What is RStudio?\nRStudio (http://www.rstudio.com/) is an open source integrated development environment (IDE) that provides a nicer graphical interface to R than does the default R GUI.\nThe figure below illustrates the RStudio interface, in it’s default configuration. For the exercises below you’ll be primarily entering commands in the “console” window. We’ll review key parts of the RStudio interface in greater detail in class.\n\n\n\n\n\nRStudio window with the panes labeled"
  },
  {
    "objectID": "R/R-getting-started.html#entering-commands-in-the-console",
    "href": "R/R-getting-started.html#entering-commands-in-the-console",
    "title": "3  Getting Started with R",
    "section": "3.3 Entering commands in the console",
    "text": "3.3 Entering commands in the console\nYou can type commands directly in the console. When you hit Return (Enter) on your keyboard the text you typed is evaluated by the R interpreter. This means that the R program reads your commands, makes sure there are no syntax errors, and then carries out any commands that were specified.\nTry evaluating the following arithmetic commands in the console:\n\n10 + 5\n10 - 5\n10 / 5\n10 * 5\n\nIf you type an incomplete command and then hit Return on your keyboard, the console will show a continuation line marked by a + symbol. For example enter the incomplete statement (10 + 5 and then hit Enter. You should see something like this.\n> (10 + 5\n+\nThe continuation line tells you that R is waiting for additional input before it evaluates what you typed. Either complete your command (e.g. type the closing parenthesis) and hit Return, or hit the “Esc” key to exit the continuation line without evaluating what you typed."
  },
  {
    "objectID": "R/R-getting-started.html#comments",
    "href": "R/R-getting-started.html#comments",
    "title": "3  Getting Started with R",
    "section": "3.4 Comments",
    "text": "3.4 Comments\nWhen working in the R console, or writing R code, the pound symbol (#) indicates the start of a comment. Anything after the #, up to the end of the current line, is ignored by the R interpretter.\n\n# This line will be ignored\n5 + 4 # the first part of this line, up to the #, will be evaluated\n\nThroughout this course I will often include short explanatory comments in my code examples.\nWhen I want to display the output generated by an R statement typed at the console I will generally use a display convention in which I prepend the results with the symbols ##.\n\n5 + 4  # same as above but with output displayed\n\n[1] 9"
  },
  {
    "objectID": "R/R-getting-started.html#using-r-as-a-calculator",
    "href": "R/R-getting-started.html#using-r-as-a-calculator",
    "title": "3  Getting Started with R",
    "section": "3.5 Using R as a Calculator",
    "text": "3.5 Using R as a Calculator\nThe simplest way to use R is as a fancy calculator. Evaluate each of the following statements in the console.\n\n10 + 2 # addition\n10 - 2 # subtraction\n10 * 2 # multiplication\n10 / 2 # division\n10 ^ 2 # exponentiation\n10 ** 2 # alternate exponentiation\npi * 2.5^2 # R knows about some constants such as Pi\n10 %% 3 # modulus operator -- gives remainder after division\n10 %/% 3 # integer division\n\nBe aware that certain operators have precedence over others. For example multiplication and division have higher precedence than addition and subtraction. Use parentheses to disambiguate potentially confusing statements.\n\n(10 + 2)/4-5   # was the output what you expected?\n(10 + 2)/(4-5) # compare the answer to the above\n\nDivision by zero produces an object that represents infinite numbers. Infinite values can be either positive or negative\n\n1/0 \n\n[1] Inf\n\n-1/0\n\n[1] -Inf\n\n\nInvalid calculations produce a objected called NaN which is short for “Not a Number”:\n\n0/0  # invalid calculation\n\n[1] NaN\n\n\n\n3.5.1 Common mathematical functions\nMany commonly used mathematical functions are built into R. Here are some examples:\n\nabs(-3)   # absolute value\n\n[1] 3\n\ncos(pi/3) # cosine\n\n[1] 0.5\n\nsin(pi/3) # sine\n\n[1] 0.8660254\n\nlog(10)   # natural logarithm\n\n[1] 2.302585\n\nlog10(10) # log base 10\n\n[1] 1\n\nlog2(10) # log base 2\n\n[1] 3.321928\n\nexp(1)    # exponential function\n\n[1] 2.718282\n\nsqrt(10)  # square root\n\n[1] 3.162278\n\n10^0.5  # same as square root\n\n[1] 3.162278"
  },
  {
    "objectID": "R/R-getting-started.html#variable-assignment",
    "href": "R/R-getting-started.html#variable-assignment",
    "title": "3  Getting Started with R",
    "section": "3.6 Variable assignment",
    "text": "3.6 Variable assignment\nAn important programming concept in all programming languages is that of “variable assignment”. Variable assignment is the act of creating labels that point to particular data values in a computers memory, which allows us to apply operations to the labels rather than directly to specific. Variable assignment is an important mechanism of abstracting and generalizing computational operations.\nVariable assignment in R is accomplished with the assignment operator, which is designated as <- (left arrow, constructed from a left angular brack and the minus sign). This is illustrated below:\n\nx <- 10  # assign the variable name 'x' the value 10\nsin(x)   # apply the sin function to the value x points to\n\n[1] -0.5440211\n\nx <- pi  # x now points to a different value\nsin(x)   # the same function call now produces a different result \n\n[1] 1.224647e-16\n\n         # note that sin(pi) == 0, but R returns a floating point value very \n         # very close to but not zero\n\n\n3.6.1 Valid variable names\nAs described in the R documentation, “A syntactically valid name consists of letters, numbers and the dot or underline characters and starts with a letter or the dot not followed by a number. Names such as ‘.2way’ are not valid, and neither are the reserved words.”\nHere are some examples of valid and invalid variable names. Mentally evaluate these based on the definition above, and then evaluate these in the R interpetter to confirm your understanding :\nx <- 10\nx.prime <- 10\nx_prime <- 10\nmy.long.variable.name <- 10\nanother_long_variable_name <- 10\n_x <- 10\n.x <- 10\n2.x <- 2 * x"
  },
  {
    "objectID": "R/R-getting-started.html#data-types",
    "href": "R/R-getting-started.html#data-types",
    "title": "3  Getting Started with R",
    "section": "3.7 Data types",
    "text": "3.7 Data types\nThe phrase “data types” refers to the representations of information that a programming language provides. In R, there are three core data types representing numbes, logical values, and strings. You can use the function typeof() to get information about an objects type in R.\n\n3.7.1 Numeric data types\nThere are three standard types of numbers in R.\n\n“double” – this is the default numeric data type, and is used to represent both real numbers and whole numbers (unless you explicitly ask for integers, see below). “double” is short for “double precision floating point value”. All of the previous computations you’ve seen up until this point used data of type double.\n::: {.cell}\ntypeof(10.0)  # real number\n::: {.cell-output .cell-output-stdout} [1] \"double\" :::\ntypeof(10)  # whole numbers default to doubles\n::: {.cell-output .cell-output-stdout} [1] \"double\" ::: :::\n“integer” – when your numeric data involves only whole numbers, you can get slighly better performance using the integer data type. You must explicitly ask for numbers to be treated as integers.\n::: {.cell}\ntypeof(as.integer(10))  # now treated as an integer\n::: {.cell-output .cell-output-stdout} [1] \"integer\" ::: :::\n“complex” – R has a built-in data type to represent complex numbers – numbers with a “real” and “imaginary” component. We won’t encounter the use of complex numbers in this course, but they do have many important uses in mathematics and engineering and also have some interesting applications in biology.\n::: {.cell}\ntypeof(1 + 0i)\n::: {.cell-output .cell-output-stdout} [1] \"complex\" :::\nsqrt(-1)      # sqrt of -1, using doubles\n::: {.cell-output .cell-output-stderr} Warning in sqrt(-1): NaNs produced :::\n::: {.cell-output .cell-output-stdout} [1] NaN :::\nsqrt(-1 + 0i) # sqrt of -1, using complex numbers\n::: {.cell-output .cell-output-stdout} [1] 0+1i ::: :::\n\n\n\n3.7.2 Logical values\nWhen we compare values to each other, our calculations no longer return “doubles” but rather TRUE and FALSE values. This is illustrated below:\n\n10 < 9  # is 10 less than 9?\n\n[1] FALSE\n\n10 > 9  # is 10 greater than 9?\n\n[1] TRUE\n\n10 <= (5 * 2) # less than or equal to?\n\n[1] TRUE\n\n10 >= pi # greater than or equal to?\n\n[1] TRUE\n\n10 == 10 # equals?\n\n[1] TRUE\n\n10 != 10 # does not equal?\n\n[1] FALSE\n\n\nTRUE and FALSE objects are of “logical” data type (known as “Booleans” in many other languages, after the mathematician George Boole).\n\ntypeof(TRUE)\ntypeof(FALSE)\nx <- FALSE\ntypeof(x)  # x points to a logical\nx <- 1\ntypeof(x)  # the variable x no longer points to a logical\n\nWhen working with numerical data, tests of equality can be tricky. For example, consider the following two comparisons:\n\n10 == (sqrt(10)^2) # Surprised by the result? See below.\n4 == (sqrt(4)^2) # Even more confused?\n\nMathematically we know that both \\((\\sqrt{10})^2 = 10\\) and \\((\\sqrt{4})^2 = 4\\) are true statements. Why does R tell us the first statement is false? What we’re running into here are the limits of computer precision. A computer can’t represent \\(\\sqrt 10\\) exactly, whereas \\(\\sqrt 4\\) can be exactly represented. Precision in numerical computing is a complex subject and a detailed discussion is beyond the scope of this course. However, it’s important to be aware of this limitation (this limitation is true of any programming language, not just R).\nTo test “near equality” R provides a function called all.equal(). This function takes two inputs – the numerical values to be compared – and returns TRUE if their values are equal up to a certain level of tolerance (defined by the built-in numerical precision of your computer).\n\nall.equal(10, sqrt(10)^2)\n\n[1] TRUE\n\n\nHere’s another example where the simple equality operator returns an unexpected result, but all.equal() produces the comparison we’re likely after.\n\nsin(pi) == 0  \n\n[1] FALSE\n\nall.equal(sin(pi), 0)  \n\n[1] TRUE\n\n\n\n3.7.2.1 Logical operators\nLogical values support Boolean operations, like logical negation (“not”), “and”, “or”, “xor”, etc. This is illustrated below:\n\n!TRUE  # logical negation -- reads as \"not x\"\n\n[1] FALSE\n\nTRUE & FALSE # AND: are x and y both TRUE?\n\n[1] FALSE\n\nTRUE | FALSE # OR: are either x or y TRUE?\n\n[1] TRUE\n\nxor(TRUE,FALSE)  # XOR: is either x or y TRUE, but not both?\n\n[1] TRUE\n\n\nThe function isTRUE can be useful for evaluating the state of a variable:\n\nx <- sample(1:10, 1) # sample a random number in the range 1 to 10\nisTRUE(x > 5)  # was the random number picked greater than 5?\n\n[1] TRUE\n\n\n\n\n\n3.7.3 Character strings\nCharacter strings (“character”) represent single textual characters or a longer sequence of characters. They are created by enclosing the characters in text either single our double quotes.\n\ntypeof(\"abc\")  # double quotes \n\n[1] \"character\"\n\ntypeof('abc')  # single quotes\n\n[1] \"character\"\n\n\nCharacter strings have a length, which can be found using the nchar function:\n\nfirst.name <- \"jasmine\"\nnchar(first.name)\n\n[1] 7\n\nlast.name <- 'smith'\nnchar(last.name)\n\n[1] 5\n\n\nThere are a number of built-in functions for manipulating character strings. Here are some of the most common ones.\n\n3.7.3.1 Joining strings\nThe paste() function joins two characters strings together:\n\npaste(first.name, last.name)  # join two strings\n\n[1] \"jasmine smith\"\n\npaste(\"abc\", \"def\")\n\n[1] \"abc def\"\n\n\nNotice that paste() adds a space between the strings? If we didn’t want the space we can call the paste() function with an optional argument called sep (short for separator) which specifies the character(s) that are inserted between the joined strings.\n\npaste(\"abc\", \"def\", sep = \"\")  # join with no space; \"\" is an empty string\n\n[1] \"abcdef\"\n\npaste0(\"abc\", \"def\") # an equivalent function with no space in newer version of R\n\n[1] \"abcdef\"\n\npaste(\"abc\", \"def\", sep = \"|\") # join with a vertical bar\n\n[1] \"abc|def\"\n\n\n\n\n3.7.3.2 Splitting strings\nThe strsplit() function allows us to split a character string into substrings according to matches to a specified split string (see ?strsplit for details). For example, we could break a sentence into it’s constituent words as follows:\n\nsentence <- \"Call me Ishmael.\"\nwords <- strsplit(sentence, \" \")  # split on space\nwords\n\n[[1]]\n[1] \"Call\"     \"me\"       \"Ishmael.\"\n\n\nNotice that strsplit() is the reverse of paste().\n\n\n3.7.3.3 Substrings\nThe substr() function allows us to extract a substring from a character object by specifying the first and last positions (indices) to use in the extraction:\n\nsubstr(\"abcdef\", 2, 5)  # get substring from characters 2 to 5\n\n[1] \"bcde\"\n\nsubstr(first.name, 1, 3) # get substring from characters 1 to       \n\n[1] \"jas\""
  },
  {
    "objectID": "R/R-getting-started.html#packages",
    "href": "R/R-getting-started.html#packages",
    "title": "3  Getting Started with R",
    "section": "3.8 Packages",
    "text": "3.8 Packages\nPackages are libraries of R functions and data that provide additional capabilities and tools beyond the standard library of functions included with R. Hundreds of people around the world have developed packages for R that provide functions and related data structures for conducting many different types of analyses.\nThroughout this course you’ll need to install a variety of packages. Here I show the basic procedure for installing new packages from the console as well as from the R Studio interface.\n\n3.8.1 Installing packages from the console\nThe function install.packages() provides a quick and conveniet way to install packages from the R console.\n\n\n3.8.2 Install the tidyverse package\nTo illustrate the use of install.packages(), we’ll install a collection of packages (a “meta-package”) called the tidyverse. Here’s how to install the tidyverse meta-package from the R console:\n\ninstall.packages(\"tidyverse\", dependencies = TRUE)\n\nThe first argument to install.packages gives the names of the package we want to install. The second argument, dependencies = TRUE, tells R to install any additional packages that tidyverse depends on.\n\n\n3.8.3 Installing packages from the RStudio dialog\nYou can also install packages using a graphical dialog provided by RStudio. To do so pick the Packages tab in RStudio, and then click the Install button.\n\n\n\n\n\nThe Packages tab in RStudio\n\n\n\n\nIn the packages entry box you can type the name of the package you wish to install. Let’s install another useful package called “stringr”. Type the package name in the “Packages” field, make sure the “Install dependencies” check box is checked, and then press the “Install” button.\n\n\n\n\n\nPackage Install Dialog\n\n\n\n\n\n\n3.8.4 Loading packages with the library() function\nOnce a package is installed on your computer, the package can be loaded into your R session using the library function. To insure our previous install commands worked correctly, let’s load one of the packages we just installed.\n\nlibrary(tidyverse)\n\nSince the tidyverse pacakge is a “meta-package” it provides some additional info about the sub-packages that got loaded.\nWhen you load tidyverse, you will also see a message about “Conflicts” as several of the functions provided in the dplyr package (a sub-package in tidyverse) conflict with names of functions provided by the “stats” package which usually gets automically loaded when you start R. The conflicting funcdtions are filter and lag. The conflicting functions in the stats package are lag and filter which are used in time series analysis. The dplyr functions are more generally useful. Furthermore, if you need these masked functions you can still access them by prefacing the function name with the name of the package (e.g. stats::filter).\nWe will use the “tidyverse” package for almost every class session and assignment in this class. Get in the habit of including the library(tidyverse) statement in all of your R documents."
  },
  {
    "objectID": "R/R-getting-started.html#the-r-help-system",
    "href": "R/R-getting-started.html#the-r-help-system",
    "title": "3  Getting Started with R",
    "section": "3.9 The R Help System",
    "text": "3.9 The R Help System\nR comes with fairly extensive documentation and a simple help system. You can access HTML versions of the R documentation under the Help tab in Rstudio. The HTML documentation also includes information on any packages you’ve installed. Take a few minutes to browse through the R HTML documentation. In addition to the HTML documentation there is also a search box where you can enter a term to search on (see red arrow in figure below).\n\n\n\n\n\nThe RStudio Help tab\n\n\n\n\n\n3.9.1 Getting help from the console\nIn addition to getting help from the RStudio help tab, you can directly search for help from the console. The help system can be invoked using the help function or the ? operator.\n\nhelp(\"log\")\n?log\n\nIf you are using RStudio, the help results will appear in the “Help” tab of the Files/Plots/Packages/Help/Viewer (lower right window by default).\nWhat if you don’t know the name of the function you want? You can use the help.search() function.\n\nhelp.search(\"log\")\n\nIn this case help.search(\"log\") returns all the functions with the string log in them. For more on help.search type ?help.search.\nOther useful help related functions include apropos() and example(), vignette(). apropos returns a list of all objects (including variable names and function names) in the current session that match the input string.\n\napropos(\"log\")\n\n [1] \"as.data.frame.logical\" \"as.logical\"            \"as.logical.factor\"    \n [4] \"dlogis\"                \"is.logical\"            \"log\"                  \n [7] \"log10\"                 \"log1p\"                 \"log2\"                 \n[10] \"logb\"                  \"Logic\"                 \"logical\"              \n[13] \"logLik\"                \"loglin\"                \"plogis\"               \n[16] \"qlogis\"                \"rlogis\"                \"SSlogis\"              \n\n\nexample() provides examples of how a function is used.\n\nexample(log)\n\n\nlog> log(exp(3))\n[1] 3\n\nlog> log10(1e7) # = 7\n[1] 7\n\nlog> x <- 10^-(1+2*1:9)\n\nlog> cbind(x, log(1+x), log1p(x), exp(x)-1, expm1(x))\n          x                                                    \n [1,] 1e-03 9.995003e-04 9.995003e-04 1.000500e-03 1.000500e-03\n [2,] 1e-05 9.999950e-06 9.999950e-06 1.000005e-05 1.000005e-05\n [3,] 1e-07 1.000000e-07 1.000000e-07 1.000000e-07 1.000000e-07\n [4,] 1e-09 1.000000e-09 1.000000e-09 1.000000e-09 1.000000e-09\n [5,] 1e-11 1.000000e-11 1.000000e-11 1.000000e-11 1.000000e-11\n [6,] 1e-13 9.992007e-14 1.000000e-13 9.992007e-14 1.000000e-13\n [7,] 1e-15 1.110223e-15 1.000000e-15 1.110223e-15 1.000000e-15\n [8,] 1e-17 0.000000e+00 1.000000e-17 0.000000e+00 1.000000e-17\n [9,] 1e-19 0.000000e+00 1.000000e-19 0.000000e+00 1.000000e-19\n\n\nThe vignette() function gives longer, more detailed documentation about libraries. Not all libraries include vignettes, but for those that do it’s usually a good place to get started. For example, the stringr package (which we installed above) includes a vignette. To read it’s vignette, type the following at the console\nvignette(\"stringr\")"
  },
  {
    "objectID": "R/R-intro-RMarkdown.html#r-notebooks",
    "href": "R/R-intro-RMarkdown.html#r-notebooks",
    "title": "4  R Markdown and R Notebooks",
    "section": "4.1 R Notebooks",
    "text": "4.1 R Notebooks\nWe’re going to create a type of R Markdown document called an “R Notebook”. The R Notebook Documentation describes R Notebooks as so: “An R Notebook is an R Markdown document with code chunks that can be executed independently and interactively, with output visible immediately beneath the input.”"
  },
  {
    "objectID": "R/R-intro-RMarkdown.html#creating-an-r-notebook",
    "href": "R/R-intro-RMarkdown.html#creating-an-r-notebook",
    "title": "4  R Markdown and R Notebooks",
    "section": "4.2 Creating an R Notebook",
    "text": "4.2 Creating an R Notebook\nTo create an R Notebook select File > New File > R Notebook from the files menu in RStudio.\n\n\n\n\n\nUsing the File menu to create a new R Notebook."
  },
  {
    "objectID": "R/R-intro-RMarkdown.html#the-default-r-notebook-template",
    "href": "R/R-intro-RMarkdown.html#the-default-r-notebook-template",
    "title": "4  R Markdown and R Notebooks",
    "section": "4.3 The default R Notebook template",
    "text": "4.3 The default R Notebook template\nThe standard template that RStudio creates for you includes a header section like the following where you can specify document properties such as the title, author, and change the look and feel of the generated HTML document.\n---\ntitle: \"R Notebook\"\noutput: html_notebook\n---\nThe header is followed by several example sections that illustrate a few of the capabilities of R Markdown. Delete these and replace them with your own code as necessary."
  },
  {
    "objectID": "R/R-intro-RMarkdown.html#code-and-non-code-blocks",
    "href": "R/R-intro-RMarkdown.html#code-and-non-code-blocks",
    "title": "4  R Markdown and R Notebooks",
    "section": "4.4 Code and Non-code blocks",
    "text": "4.4 Code and Non-code blocks\nR Markdown documents are divided into code blocks (also called “chunks”) and non-code blocks. Code blocks are sets of R commands that will be evalauted when the R Markdown document is run or “knitted” (see below). Non-code blocks include explanatory text, embedded images, etc. The default notebook template includes both code and non-code blocks.\n\n4.4.1 Non-code blocks\nThe first bit of text in the default notebook template is a non-code block that tells you how to use the notebook:\nThis is an [R Markdown](http://rmarkdown.rstudio.com) Notebook. \nWhen you execute code within the notebook, the results appear\nbeneath the code. \n\nTry executing this chunk by clicking the *Run* button within the chunk \nor by placing your cursor inside it and pressing *Cmd+Shift+Enter*. \nThe text of non-code blocks can include lightweight markup information that can be used to format HTML or PDF output generated from the R Markdown document. Here are some examples:\n# Simple textual formatting \n\nThis is a paragraph with plain text.  Nothing fancy will happen here.\n\nThis is a second paragraph with *italic*, **bold**, and `verbatim` text. \n\n# Lists\n\n## Bullet points lists\n\nThis is a list with bullet points:\n\n  * Item a\n  * Item b\n  * Item c\n\n## Numbered lists\n  \nThis is a numbered list:\n\n  1. Item 1\n  #. Item 2\n  #. Item 3\n  \n## Mathematics\n\nR Markdown supports mathematical equations, formatted according to LaTeX\nconventions. Dollar signs ($) are used to offset mathematics \nlike so:  $x^2 + y^2 = z^2$.\n\nNotice from the example above that R Markdown supports LaTeX style formatting of mathematical equations. For example, $x^2 + y^2 = z^2$ appears as \\(x^2 + y^2 = z^2\\).\n\n\n4.4.2 Code blocks\nCode blocks are delimited by matching sets of three backward ticks (```). Everything within a code block is interpretted as an R command and is evaluated by the R interpretter. Here’s the first code block in the default notebook template:\n```\n{r}\nplot(cars)\n```"
  },
  {
    "objectID": "R/R-intro-RMarkdown.html#running-a-code-chunk",
    "href": "R/R-intro-RMarkdown.html#running-a-code-chunk",
    "title": "4  R Markdown and R Notebooks",
    "section": "4.5 Running a code chunk",
    "text": "4.5 Running a code chunk\nYou can run a single code block by clicking the small green “Run” button in the upper right hand corner of the code block as shown in the image below.\n\n\n\n\n\nClick the Run button to execute a code chunk.\n\n\n\n\nIf you click this button the commands within this code block are executed, and any generated output is shown below the code block.\nTry running the first code block in the default template now. After the code chunk is executed you should see a plot embedded in your R Notebook as shown below:\n\n\n\n\n\nAn R Notebook showing an embedded plot after executing a code chunk."
  },
  {
    "objectID": "R/R-intro-RMarkdown.html#running-all-code-chunks-above",
    "href": "R/R-intro-RMarkdown.html#running-all-code-chunks-above",
    "title": "4  R Markdown and R Notebooks",
    "section": "4.6 Running all code chunks above",
    "text": "4.6 Running all code chunks above\nNext to the “Run” button in each code chunk is a button for “Run all chunks above” (see figure below). This is useful when the code chunk you’re working on depends on calculations in earlier code chunks, and you want to evaluated those earlier code chunks prior to running the focal code chunk.\n\n\n\n\n\nUse the ‘Run all chunks above’ button to evaluate all previous code chunks."
  },
  {
    "objectID": "R/R-intro-RMarkdown.html#knitting-r-markdown-to-html",
    "href": "R/R-intro-RMarkdown.html#knitting-r-markdown-to-html",
    "title": "4  R Markdown and R Notebooks",
    "section": "4.7 “Knitting” R Markdown to HTML",
    "text": "4.7 “Knitting” R Markdown to HTML\nSave your R Notebook as first_rnotebook.Rmd (RStudio will automatically add the .Rmd extension so you don’t need to type it). You can generate an HTML version of your notebook by clicking the “Preview” menu on the Notebook taskbar and then choosing “Knit to HTML” (see image below).\n\n\n\n\n\nUse the ‘Knit to HTML’ menu to generate HTML output from your R Notebook\n\n\n\n\nWhen an RMarkdown document is “knit”, all of the code and non-code blocks are executed in a “clean” environment, in order from top to bottom. An output file is generated (HTML or one of the other available output types) that shows the results of executing the notebook. By default RStudio will pop-up a window showing you the HTML output you generated.\nKnitting a document is a good way to make sure your analysis is reproducible. If your code compiles correctly when the document is knit, and produces the expected output, there’s a good chance that someone else will be able to reproduce your analyses independently starting with your R Notebook document (after accounting for differences in file locations)."
  },
  {
    "objectID": "R/R-intro-RMarkdown.html#sharing-your-reproducible-r-notebook",
    "href": "R/R-intro-RMarkdown.html#sharing-your-reproducible-r-notebook",
    "title": "4  R Markdown and R Notebooks",
    "section": "4.8 Sharing your reproducible R Notebook",
    "text": "4.8 Sharing your reproducible R Notebook\nTo share your R Notebook with someone else you just need to send them the source R Markdown file (i.e. the file with the .Rmd extension). Assuming they have access to the same source data, another user should be able to open the notebook file in RStudio and regenerate your analyses by evaluating the individual code chunks or knitting the document.\nIn this course you will be submitting homework assignments in the form of R Notebook markdown files."
  },
  {
    "objectID": "R/R-dplyr-intro.html#libraries",
    "href": "R/R-dplyr-intro.html#libraries",
    "title": "5  Introduction to dplyr",
    "section": "5.1 Libraries",
    "text": "5.1 Libraries\nBoth readr and dplyr are members of the tidyverse, so a single invocation of library() makes the functions defined in these two packages available for our use:\n\nlibrary(tidyverse)"
  },
  {
    "objectID": "R/R-dplyr-intro.html#reading-data-with-the-readr-package",
    "href": "R/R-dplyr-intro.html#reading-data-with-the-readr-package",
    "title": "5  Introduction to dplyr",
    "section": "5.2 Reading data with the readr package",
    "text": "5.2 Reading data with the readr package\nThe readr package defines a number of functions for reading data tables from common file formats like Comma-Separated-Value (CSV) and Tab-Separated-Value (TSV) files.\nThe two most frequently used readr functions we’ll use in this class are read_csv() and read_tsv() for reading CSV and TSV files respectively. There are some variants of these basic function, which you can read about by invoking the help system (?read_csv).\n\n5.2.1 Reading Excel files\nThe tidyverse also includes a package called readxl which can be used to read Excel spreadsheets (recent versions with .xls and .xlsx extensions). Excel files are somewhat more complicated to deal with because they can include separate “sheets”. We won’t use readxl in this class, but documentation and examples of how readxl is used can be found at the page linked above.\n\n\n5.2.2 Example data: NC Births\nFor today’s hands on session we’ll use a data set that contains information on 150 cases of mothers and their newborns in North Carolina in 2004. This data set is available at the following URL:\n\nhttps://github.com/Bio723-class/example-datasets/raw/master/nc-births.txt\n\nThe births data is a TSV file, so we’ll use the read_tsv() function to read it:\n\nbirths <- read_tsv(\"https://github.com/Bio723-class/example-datasets/raw/master/nc-births.txt\")\n\nRows: 150 Columns: 9\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \"\\t\"\nchr (3): premature, sexBaby, smoke\ndbl (6): fAge, mAge, weeks, visits, gained, weight\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\nNotice that when you used read_tsv() the function printed information about how it “parsed” the data (i.e. the types it assigned to each of the columns).\nThe variables in the data set are:\n\nfather’s age (fAge),\nmother’s age (mAge),\n\nweeks of gestation (weeks)\nwhether the birth was premature or full term (premature)\nnumber of OB/GYN visits (visits)\nmother’s weight gained in pounds (gained)\nbabies birth weight (weight)\nsex of the baby (sexBaby)\nwhether the mother was a smoker (smoke).\n\nNotice too that we read the TSV file directly from a remote location via a URL. If instead, you wanted to load a local file on your computer you would specify the “path” – i.e. the location on your hard drive where you stored the file. For example, here is how I would load the same file if it was stored in the Downloads directory on my Mac laptop:\n\n# load the data from a local file\nbirths <- read_tsv(\"/Users/pmagwene/Downloads/nc-births.txt\")"
  },
  {
    "objectID": "R/R-dplyr-intro.html#a-note-on-tibbles",
    "href": "R/R-dplyr-intro.html#a-note-on-tibbles",
    "title": "5  Introduction to dplyr",
    "section": "5.3 A note on “tibbles”",
    "text": "5.3 A note on “tibbles”\nYou may have noticed that most of the functions defined in tidyverse related packages return not data frames, but rather something called a “tibble”. You can think about tibbles as light-weight data frames. In fact if you ask about the “class” of a tibble you’ll see that it includes data.frame as one of it’s classes as well as tbl and tbl_df.\n\nclass(births)\n\n[1] \"spec_tbl_df\" \"tbl_df\"      \"tbl\"         \"data.frame\" \n\n\nThere are some minor differences between data frame and tibbles. For example, tibbles print differently in the console and don’t automatically change variable names and types in the same way that standard data frames do. Usually tibbles can be used wherever a standard data frame is expected, but you may occasionally find a function that only works with a standard data frame. It’s easy to convert a tibble to a standard data frame using the as.data.frame function:\n\nbirths.std.df <- as.data.frame(births)\n\nFor more details about tibbles, see the Tibbles chapter in R for Data Analysis."
  },
  {
    "objectID": "R/R-dplyr-intro.html#data-filtering-and-transformation-with-dplyr",
    "href": "R/R-dplyr-intro.html#data-filtering-and-transformation-with-dplyr",
    "title": "5  Introduction to dplyr",
    "section": "5.4 Data filtering and transformation with dplyr",
    "text": "5.4 Data filtering and transformation with dplyr\ndplyr is powerful tool for data filter and transformation. In the same way that ggplot2 attempts to provide a “grammar of graphics”, dplyr aims to provide a “grammar of data manipulation”. In today’s material we will see how dplyr complements and simplifies standard data frame indexing and subsetting operations. However, dplyr is focused only on data frames and doesn’t completely replace the basic subsetting operations, and so being adept with both dplyr and the indexing approaches we’ve seen previously is important. If you’re curious about the name “dplyr”, the package’s originator Hadley Wickham says it’s supposed to invoke the idea of pliers for data frames (Github: Meaning of dplyrs name)"
  },
  {
    "objectID": "R/R-dplyr-intro.html#dplyrs-verbs",
    "href": "R/R-dplyr-intro.html#dplyrs-verbs",
    "title": "5  Introduction to dplyr",
    "section": "5.5 dplyr’s “verbs”",
    "text": "5.5 dplyr’s “verbs”\nThe primary functions in the dplyr package can be thought of as a set of “verbs”, each verb corresponding to a common data manipulation task. Some of the most frequently used verbs/functions in dplyr include:\n\nselect – select columns\nfilter – filter rows\nmutate – create new columns\narrange– reorder rows\nsummarize – summarize values\ngroup_by – split data frame on some grouping variable. Can be powerfully combined with summarize\n\nAll of these functions return new data frames rather than modifying the existing data frame (though some of the functions support in place modification of data frames via optional arguments).We illustrate these below by example using the NC births data.\n\n5.5.1 select\nThe select function subsets the columns (variables) of a data frame. For example, to select just the weeks and weight columns from the births data set we could do:\n\n# note I'm prefixing select with the package name (dplyr)\n# to avoid name clashes with built-in select function\nwks.weight <- dplyr::select(births, weeks, weight)\ndim(wks.weight)  # dim should be 50 x 2\n\n[1] 150   2\n\nhead(wks.weight)\n\n# A tibble: 6 × 2\n  weeks weight\n  <dbl>  <dbl>\n1    39   6.88\n2    39   7.69\n3    40   8.88\n4    40   9   \n5    40   7.94\n6    40   8.25\n\n\nThe equivalent using standard indexing would be:\n\nwks.wt.alt <- births[c(\"weeks\", \"weight\")]\ndim(wks.wt.alt)\n\n[1] 150   2\n\nhead(wks.wt.alt)\n\n# A tibble: 6 × 2\n  weeks weight\n  <dbl>  <dbl>\n1    39   6.88\n2    39   7.69\n3    40   8.88\n4    40   9   \n5    40   7.94\n6    40   8.25\n\n\nNotes:\n* The first argument to all of the dplyr functions is the data frame you’re operating on\n\nWhen using functions defined in dplyr and ggplot2 variable names are (usually) not quoted or used with the $ operator. This is a design feature of these libraries and makes it easier to carry out interactive analyes because it saves a fair amount of typing.\n\n\n\n5.5.2 filter\nThe filter function returns those rows of the data set that meet the given logical criterion.\nFor example, to get all the premature babies in the data set we could use filter as so:\n\npremies <- filter(births, premature == \"premie\")\ndim(premies)\n\n[1] 21  9\n\n\nThe equivalent using standard indexing would be:\n\npremies.alt <- births[births$premature == \"premie\",] \n\nThe filter function will work with more than one logical argument, and these are joined together using Boolean AND logic (i.e. intersection). For example, to find those babies that were premature and whose mothers were smokers we could do:\n\nsmoking.premies <- filter(births, premature == \"premie\", smoke == \"smoker\")\n\nThe equivalent call using standard indexing is:\n\n# don't forget the trailing comma to indicate rows!\nsmoking.premies.alt <- births[(births$premature == \"premie\") & (births$smoke == \"smoker\"),]\n\nfilter also accepts logical statements chained together using the standard Boolean operators. For example, to find babies who were premature or whose moms were older than 35 you could use the OR operator |:\n\npremies.or.oldmom <- filter(births, premature == \"premie\" | fAge > 35)\n\n\n\n5.5.3 mutate\nThe mutate function creates a new data frame that is the same as input data frame but with additional variables (columns) as specified by the function arguments. In the example below, I create two new variables, weight.in.kg and a mom.smoked:\n\n# to make code more readable it's sometime useful to spread out\n# function arguments over multiple lines like I've done here\nbirths.plus <- mutate(births, \n                      weight.in.kg = weight / 2.2,\n                      mom.smoked = (smoke == \"smoker\"))\n\nhead(births.plus)\n\n# A tibble: 6 × 11\n   fAge  mAge weeks premature visits gained weight sexBaby smoke weigh…¹ mom.s…²\n  <dbl> <dbl> <dbl> <chr>      <dbl>  <dbl>  <dbl> <chr>   <chr>   <dbl> <lgl>  \n1    31    30    39 full term     13      1   6.88 male    smok…    3.13 TRUE   \n2    34    36    39 full term      5     35   7.69 male    nons…    3.50 FALSE  \n3    36    35    40 full term     12     29   8.88 male    nons…    4.04 FALSE  \n4    41    40    40 full term     13     30   9    female  nons…    4.09 FALSE  \n5    42    37    40 full term     NA     10   7.94 male    nons…    3.61 FALSE  \n6    37    28    40 full term     12     35   8.25 male    smok…    3.75 TRUE   \n# … with abbreviated variable names ¹​weight.in.kg, ²​mom.smoked\n\n\nThe equivalent using standard indexing would be to create a new data frame from births, appending the new variables to the end as so:\n\nbirths.plus.alt <- data.frame(births,\n                              weight.in.kg = births$weight / 2.2,\n                              mom.smoked = (births$smoke == \"smoker\"))\n\n\n\n5.5.4 arrange\nArrange creates a new data frame where the rows are sorted according to their values for one or more variables. For example, to sort by mothers age we could do:\n\nyoung.moms.first <- arrange(births, mAge)\nhead(young.moms.first)\n\n# A tibble: 6 × 9\n   fAge  mAge weeks premature visits gained weight sexBaby smoke    \n  <dbl> <dbl> <dbl> <chr>      <dbl>  <dbl>  <dbl> <chr>   <chr>    \n1    18    15    37 full term     12     76   8.44 male    nonsmoker\n2    NA    16    40 full term      4     12   6    female  nonsmoker\n3    21    16    38 full term     15     75   7.56 female  smoker   \n4    26    17    38 full term     11     30   9.5  female  nonsmoker\n5    17    17    29 premie         4     10   2.63 female  nonsmoker\n6    20    17    40 full term     17     38   7.19 male    nonsmoker\n\n\nThe equivalent to arrange using standard indexing would be to use the information returned by the order function:\n\nyoung.moms.first.alt <- births[order(births$mAge),]\nhead(young.moms.first.alt)\n\n# A tibble: 6 × 9\n   fAge  mAge weeks premature visits gained weight sexBaby smoke    \n  <dbl> <dbl> <dbl> <chr>      <dbl>  <dbl>  <dbl> <chr>   <chr>    \n1    18    15    37 full term     12     76   8.44 male    nonsmoker\n2    NA    16    40 full term      4     12   6    female  nonsmoker\n3    21    16    38 full term     15     75   7.56 female  smoker   \n4    26    17    38 full term     11     30   9.5  female  nonsmoker\n5    17    17    29 premie         4     10   2.63 female  nonsmoker\n6    20    17    40 full term     17     38   7.19 male    nonsmoker\n\n\nWhen using arrange, multiple sorting variables can be specified:\n\nsorted.by.moms.and.dads <- arrange(births, mAge, fAge)\nhead(sorted.by.moms.and.dads)\n\n# A tibble: 6 × 9\n   fAge  mAge weeks premature visits gained weight sexBaby smoke    \n  <dbl> <dbl> <dbl> <chr>      <dbl>  <dbl>  <dbl> <chr>   <chr>    \n1    18    15    37 full term     12     76   8.44 male    nonsmoker\n2    21    16    38 full term     15     75   7.56 female  smoker   \n3    NA    16    40 full term      4     12   6    female  nonsmoker\n4    17    17    29 premie         4     10   2.63 female  nonsmoker\n5    20    17    40 full term     17     38   7.19 male    nonsmoker\n6    26    17    38 full term     11     30   9.5  female  nonsmoker\n\n\nIf you want to sort in descending order, you can combing arrange with the desc (=descend) function, also defined in dplyr:\n\nold.moms.first <- arrange(births, desc(mAge))\nhead(old.moms.first)\n\n# A tibble: 6 × 9\n   fAge  mAge weeks premature visits gained weight sexBaby smoke    \n  <dbl> <dbl> <dbl> <chr>      <dbl>  <dbl>  <dbl> <chr>   <chr>    \n1    NA    41    33 premie        13      0   5.69 female  nonsmoker\n2    41    40    40 full term     13     30   9    female  nonsmoker\n3    33    40    36 premie        13     23   7.81 female  nonsmoker\n4    40    40    38 full term     13     38   7.31 male    nonsmoker\n5    46    39    38 full term     10     35   6.75 male    smoker   \n6    NA    38    32 premie        10     16   2.19 female  smoker   \n\n\n\n\n5.5.5 summarize\nsummarize applies a function of interest to one or more variables in a data frame, reducing a vector of values to a single value and returning the results in a data frame. This is most often used to calculate statistics like means, medians, count, etc. As we’ll see below, this is powerful when combined with the group_by function.\n\nsummarize(births, \n          mean.wt = mean(weight), \n          median.wks = median(weeks))\n\n# A tibble: 1 × 2\n  mean.wt median.wks\n    <dbl>      <dbl>\n1    7.05         39\n\n\nYou’ll need to be diligent if your data has missing values (NAs). For example, by default the mean function returns NA if any of the input values are NA:\n\nsummarize(births, \n          mean.gained = mean(gained))\n\n# A tibble: 1 × 1\n  mean.gained\n        <dbl>\n1          NA\n\n\nHowever, if you read the mean docs (?mean) you’ll see that there is an na.rm argument that indicates whether NA values should be removed before computing the mean. This is what we want so we instead call summarize as follows:\n\nsummarize(births, \n          mean.gained = mean(gained, na.rm = TRUE))\n\n# A tibble: 1 × 1\n  mean.gained\n        <dbl>\n1        32.5\n\n\n\n\n5.5.6 group_by\nThe group_by function implicitly adds grouping information to a data frame.\n\n# group the births by whether mom smoked or not\nby_smoking <- group_by(births, smoke)\n\nThe object returned by group_by is a “grouped data frame”:\n\nclass(by_smoking)\n\n[1] \"grouped_df\" \"tbl_df\"     \"tbl\"        \"data.frame\"\n\n\nSome functions, like count() and summarize() (see below) know how to use the grouping information. For example, to count the number of births conditional on mother smoking status we could do:\n\ncount(by_smoking)\n\n# A tibble: 2 × 2\n# Groups:   smoke [2]\n  smoke         n\n  <chr>     <int>\n1 nonsmoker   100\n2 smoker       50\n\n\ngroup_by also works with multiple grouping variables, with each added grouping variable specified as an additional argument:\n\nby_smoking.and.mAge <- group_by(births, smoke, mAge > 35)\n\n\n\n5.5.7 Combining grouping and summarizing\nGrouped data frames can be combined with the summarize function we saw above. For example, if we wanted to calculate mean birth weight, broken down by whether the baby’s mother smoked or not we could call summarize with our by_smoking grouped data frame:\n\nsummarize(by_smoking, mean.wt = mean(weight))\n\n# A tibble: 2 × 2\n  smoke     mean.wt\n  <chr>       <dbl>\n1 nonsmoker    7.18\n2 smoker       6.78\n\n\nSimilarly to get the mean birth weight of children conditioned on mothers smoking status and age:\n\nsummarize(by_smoking.and.mAge, mean(weight))\n\n`summarise()` has grouped output by 'smoke'. You can override using the\n`.groups` argument.\n\n\n# A tibble: 4 × 3\n# Groups:   smoke [2]\n  smoke     `mAge > 35` `mean(weight)`\n  <chr>     <lgl>                <dbl>\n1 nonsmoker FALSE                 7.17\n2 nonsmoker TRUE                  7.26\n3 smoker    FALSE                 6.83\n4 smoker    TRUE                  6.30\n\n\n\n\n5.5.8 Scoped variants of mutate and summarize\nBoth the mutate() and summarize() functions provide “scoped” alternatives, that allow us to apply the operation on a selection of variables. These variants are often used in combination with grouping. We’ll look at the summarize versions – summarize_all(), summarize_at(), and summarize_if(). See the documentation (?mutate_all) for descriptions of the mutate versions.\n\n5.5.8.1 summarize_all()\nsummarize_all() applies a one or more functions to all columns in a data frame. Here we illustrate a simple version of this with the iris data:\n\n# group by species\nby_species <- group_by(iris, Species)\n# calculate the mean of every variable, grouped by species\nsummarize_all(by_species, mean)  \n\n# A tibble: 3 × 5\n  Species    Sepal.Length Sepal.Width Petal.Length Petal.Width\n  <fct>             <dbl>       <dbl>        <dbl>       <dbl>\n1 setosa             5.01        3.43         1.46       0.246\n2 versicolor         5.94        2.77         4.26       1.33 \n3 virginica          6.59        2.97         5.55       2.03 \n\n\nNote that if we try and apply summarize_all() in the same way to the grouped data frame by_smoking we’ll get a bunch of warning messages:\n\nsummarize_all(by_smoking, mean)\n\n# A tibble: 2 × 9\n  smoke      fAge  mAge weeks premature visits gained weight sexBaby\n  <chr>     <dbl> <dbl> <dbl>     <dbl>  <dbl>  <dbl>  <dbl>   <dbl>\n1 nonsmoker    NA  26.9  38.6        NA   NA       NA   7.18      NA\n2 smoker       NA  26    38.5        NA   10.8     NA   6.78      NA\n\n\nHere’s an example of one of these warnings:\nWarning messages:\n1: In mean.default(premature) :\n  argument is not numeric or logical: returning NA\nThis message is telling us that we can’t apply the mean() function to the data frame column premature because this is not a numerical or logical vector. Despite this and the other similar warnings, summarize_all() does return a result, but the means for any non-numeric values are replaced with NAs, as shown below:\n# A tibble: 2 x 9\n  smoke      fAge  mAge weeks premature visits gained weight sexBaby\n  <chr>     <dbl> <dbl> <dbl>     <dbl>  <dbl>  <dbl>  <dbl>   <dbl>\n1 nonsmoker    NA  26.9  38.6        NA   NA       NA   7.18      NA\n2 smoker       NA  26.0  38.5        NA   10.8     NA   6.78      NA\nIf you examine the output above, you’ll see that there are several variables that are numeric, however we still got NAs when we calculated the grouped means. This is because those variables contain NA values. The mean function has an optional argument, na.rm, which tells the function to remove any missing data before calculating the mean. Thus we can modify our call to summarize_all as follows:\n\n# calculate mean of all variables, grouped by smoking status\nsummarize_all(by_smoking, mean, na.rm = TRUE)\n\nWarning in mean.default(premature, na.rm = TRUE): argument is not numeric or\nlogical: returning NA\n\nWarning in mean.default(premature, na.rm = TRUE): argument is not numeric or\nlogical: returning NA\n\n\nWarning in mean.default(sexBaby, na.rm = TRUE): argument is not numeric or\nlogical: returning NA\n\nWarning in mean.default(sexBaby, na.rm = TRUE): argument is not numeric or\nlogical: returning NA\n\n\n# A tibble: 2 × 9\n  smoke      fAge  mAge weeks premature visits gained weight sexBaby\n  <chr>     <dbl> <dbl> <dbl>     <dbl>  <dbl>  <dbl>  <dbl>   <dbl>\n1 nonsmoker  29.8  26.9  38.6        NA   11.9   32.5   7.18      NA\n2 smoker     29.7  26    38.5        NA   10.8   32.3   6.78      NA\n\n\nNote that the non-numeric data columns still lead to NA values.\n\n\n5.5.8.2 summarize_if()\nsummarize_if() is similar to summarize_all(), except it only applies the function of interest to those variables that match a particular predicate (i.e. are TRUE for a particular TRUE/FALSE test).\nHere we use summarize_if() to apply the mean() function to only those variables (columns) that are numeric.\n\n# calculate mean of all numeric variables, grouped by smoking status\nsummarize_if(by_smoking, is.numeric, mean, na.rm = TRUE)\n\n# A tibble: 2 × 7\n  smoke      fAge  mAge weeks visits gained weight\n  <chr>     <dbl> <dbl> <dbl>  <dbl>  <dbl>  <dbl>\n1 nonsmoker  29.8  26.9  38.6   11.9   32.5   7.18\n2 smoker     29.7  26    38.5   10.8   32.3   6.78\n\n\n\n\n5.5.8.3 summarize_at()\nsummarize_at() allows us to apply functions of interest only to specific variables.\n\n# calculate mean of gained and weight variables, grouped by smoking status\nsummarize_at(by_smoking, c(\"gained\", \"weight\"), mean, na.rm = TRUE)\n\n# A tibble: 2 × 3\n  smoke     gained weight\n  <chr>      <dbl>  <dbl>\n1 nonsmoker   32.5   7.18\n2 smoker      32.3   6.78\n\n\nAll three of the scoped summarize functions can also be used to apply multiple functions, by wrapping the function names in a call to dplyr::funs():\n\n# calculate mean and std deviation of \n# gained and weight variables, grouped by smoking status\nsummarize_at(by_smoking, c(\"gained\", \"weight\"), funs(mean, sd), na.rm = TRUE)\n\nWarning: `funs()` was deprecated in dplyr 0.8.0.\nℹ Please use a list of either functions or lambdas:\n\n# Simple named list: list(mean = mean, median = median)\n\n# Auto named with `tibble::lst()`: tibble::lst(mean, median)\n\n# Using lambdas list(~ mean(., trim = .2), ~ median(., na.rm = TRUE))\n\n\n# A tibble: 2 × 5\n  smoke     gained_mean weight_mean gained_sd weight_sd\n  <chr>           <dbl>       <dbl>     <dbl>     <dbl>\n1 nonsmoker        32.5        7.18      15.2      1.43\n2 smoker           32.3        6.78      16.6      1.60\n\n\nsummarize_at() accepts as the the argument for variables a character vector of column names, a numeric vector of column positions, or a list of columns generated by the dplyr::vars() function, which can be be used as so:\n\n# reformatted to promote readability of arguments\nsummarize_at(by_smoking, \n             vars(gained, weight),\n             funs(mean, sd),\n             na.rm = TRUE)\n\n# A tibble: 2 × 5\n  smoke     gained_mean weight_mean gained_sd weight_sd\n  <chr>           <dbl>       <dbl>     <dbl>     <dbl>\n1 nonsmoker        32.5        7.18      15.2      1.43\n2 smoker           32.3        6.78      16.6      1.60\n\n\n\n\n\n5.5.9 Combining summarize with grouping aesthetics in ggplot2\nWe’ve already seen an instance of grouping (conditioning) when we used aesthetics like color or fill to distinguish subgroups in different types of statistical graphics. Below is an example where we integrate information from a group_by/summarize operation into a plot:\n\n# calculate mean weights, conditioned on smoking status\nwt.by.smoking <- \n  summarize(by_smoking, mean_weight = mean(weight, na.rm = TRUE))\n\n# create density plot for all the data\n# and then use geom_vline to draw vertical lines at the means for\n# each group\nggplot(births) + \n  geom_density(aes(x = weight, color = smoke)) + # data drawn from births\n  geom_vline(data = wt.by.smoking,  # note use of different data frame!\n             mapping = aes(xintercept = mean_weight, color = smoke),\n             linetype = 'dashed')"
  },
  {
    "objectID": "R/R-dplyr-intro.html#pipes",
    "href": "R/R-dplyr-intro.html#pipes",
    "title": "5  Introduction to dplyr",
    "section": "5.6 Pipes",
    "text": "5.6 Pipes\ndplyr includes a very useful operator available called a pipe available to us. Pipes are powerful because they allow us to chain together sets of operations in a very intuitive fashion while minimizing nested function calls. We can think of pipes as taking the output of one function and feeding it as the first argument to another function call, where we’ve already specified the subsequent arguments.\nPipes are actually defined in another packaged called magrittr. We’ll look at the basic pipe operator and then look at a few additional “special” pipes that magrittr provides.\n\n5.6.1 Install and load magrittr\nIn magrittr in not already installed, install it via the command line or the RStudio GUI. Having done so, you will need to load magrittr via the library() function:\n\nlibrary(magrittr)\n\n\n\n5.6.2 The basic pipe operator\nThe pipe operator is designated by %>%. Using pipes, the expression x %>% f() is equivalent to f(x) and the expression x %>% f(y) is equivalent to f(x,y). The documentation on pipes (see ?magrittr) uses the notation lhs %>% rhs where lhs and rhs are short for “left-hand side” and “right-hand side” respectively. I’ll use this same notation in some of the explanations that follow.\n\nbirths %>% head()   # same as head(births)\n\n# A tibble: 6 × 9\n   fAge  mAge weeks premature visits gained weight sexBaby smoke    \n  <dbl> <dbl> <dbl> <chr>      <dbl>  <dbl>  <dbl> <chr>   <chr>    \n1    31    30    39 full term     13      1   6.88 male    smoker   \n2    34    36    39 full term      5     35   7.69 male    nonsmoker\n3    36    35    40 full term     12     29   8.88 male    nonsmoker\n4    41    40    40 full term     13     30   9    female  nonsmoker\n5    42    37    40 full term     NA     10   7.94 male    nonsmoker\n6    37    28    40 full term     12     35   8.25 male    smoker   \n\nbirths %>% head     # you can even leave the parentheses out\n\n# A tibble: 6 × 9\n   fAge  mAge weeks premature visits gained weight sexBaby smoke    \n  <dbl> <dbl> <dbl> <chr>      <dbl>  <dbl>  <dbl> <chr>   <chr>    \n1    31    30    39 full term     13      1   6.88 male    smoker   \n2    34    36    39 full term      5     35   7.69 male    nonsmoker\n3    36    35    40 full term     12     29   8.88 male    nonsmoker\n4    41    40    40 full term     13     30   9    female  nonsmoker\n5    42    37    40 full term     NA     10   7.94 male    nonsmoker\n6    37    28    40 full term     12     35   8.25 male    smoker   \n\nbirths %>% head(10) # same as head(births, 10)\n\n# A tibble: 10 × 9\n    fAge  mAge weeks premature visits gained weight sexBaby smoke    \n   <dbl> <dbl> <dbl> <chr>      <dbl>  <dbl>  <dbl> <chr>   <chr>    \n 1    31    30    39 full term     13      1   6.88 male    smoker   \n 2    34    36    39 full term      5     35   7.69 male    nonsmoker\n 3    36    35    40 full term     12     29   8.88 male    nonsmoker\n 4    41    40    40 full term     13     30   9    female  nonsmoker\n 5    42    37    40 full term     NA     10   7.94 male    nonsmoker\n 6    37    28    40 full term     12     35   8.25 male    smoker   \n 7    35    35    28 premie         6     29   1.63 female  nonsmoker\n 8    28    21    35 premie         9     15   5.5  female  smoker   \n 9    22    20    32 premie         5     40   2.69 male    smoker   \n10    36    25    40 full term     13     34   8.75 female  nonsmoker\n\n\nMultiple pipes can be chained together, such that x %>% f() %>% g() %>% h() is equivalent to h(g(f(x))).\n\n# equivalent to: head(arrange(births, weight), 10)\nbirths %>% arrange(weight) %>% head(10) \n\n# A tibble: 10 × 9\n    fAge  mAge weeks premature visits gained weight sexBaby smoke    \n   <dbl> <dbl> <dbl> <chr>      <dbl>  <dbl>  <dbl> <chr>   <chr>    \n 1    35    35    28 premie         6     29   1.63 female  nonsmoker\n 2    NA    18    33 premie         7     40   1.69 male    smoker   \n 3    NA    38    32 premie        10     16   2.19 female  smoker   \n 4    17    17    29 premie         4     10   2.63 female  nonsmoker\n 5    22    20    32 premie         5     40   2.69 male    smoker   \n 6    38    37    26 premie         5     25   3.63 male    nonsmoker\n 7    25    22    34 premie        10     20   3.75 male    nonsmoker\n 8    NA    24    38 full term     16     50   3.75 female  nonsmoker\n 9    30    25    35 premie        15     40   4.5  male    smoker   \n10    19    20    34 premie        13      6   4.5  male    nonsmoker\n\n\nWhen there are multiple piping operations, I like to arrange the statements vertically to help emphasize the flow of processing and to facilitate debugging and/or modification. I would usually rearrange the above code block as follows:\n\nbirths %>%\n  arrange(weight) %>%\n  head(10)\n\n# A tibble: 10 × 9\n    fAge  mAge weeks premature visits gained weight sexBaby smoke    \n   <dbl> <dbl> <dbl> <chr>      <dbl>  <dbl>  <dbl> <chr>   <chr>    \n 1    35    35    28 premie         6     29   1.63 female  nonsmoker\n 2    NA    18    33 premie         7     40   1.69 male    smoker   \n 3    NA    38    32 premie        10     16   2.19 female  smoker   \n 4    17    17    29 premie         4     10   2.63 female  nonsmoker\n 5    22    20    32 premie         5     40   2.69 male    smoker   \n 6    38    37    26 premie         5     25   3.63 male    nonsmoker\n 7    25    22    34 premie        10     20   3.75 male    nonsmoker\n 8    NA    24    38 full term     16     50   3.75 female  nonsmoker\n 9    30    25    35 premie        15     40   4.5  male    smoker   \n10    19    20    34 premie        13      6   4.5  male    nonsmoker\n\n\n\n\n5.6.3 An example without pipes\nTo illustrate how pipes help us, first let’s look at an example set of analysis steps without using pipes. Let’s say we wanted to explore the relationship between father’s age and baby’s birth weight. We’ll start this process of exploration by generating a bivariate scatter plot. Being good scientists we want to express our data in SI units, so we’ll need to converts pounds to kilograms. You’ll also recall that a number of the cases have missing data on father’s age, so we’ll want to remove those before we plot them. Here’s how we might accomplish these steps:\n\n# add a new column for weight in kg\nbirths.kg <- mutate(births, weight.kg = weight / 2.2)\n\n# filter out the NA fathers\nfiltered.births <- filter(births.kg, !is.na(fAge))\n\n# create our plot\nggplot(filtered.births, aes(x = fAge, y = weight.kg)) + \n  geom_point() + \n  labs(x = \"Father's Age (years)\", y = \"Birth Weight (kg)\")\n\n\n\n\nNotice that we created two “temporary” data frames along the way – births.kg and filtered.births. These probably aren’t of particular interest to us, but we needed to generate them to build the plot we wanted. If you were particularly masochistic you could avoid these temporary data frames by using nested functions call like this:\n\n# You SHOULD NOT write nested code like this.\n# Code like this is hard to debug and understand!\nggplot(filter(mutate(births, weight.kg = weight / 2.2), !is.na(fAge)), \n       aes(x = fAge, y = weight.kg)) + \n  geom_point() + \n  labs(x = \"Father's Age (years)\", y = \"Birth Weight (kg)\")\n\n\n\n5.6.4 The same example using pipes\nThe pipe operator makes the output of one statement (lhs) as the first input of a following function (rhs). This simplifies the above example to:\n\nbirths %>%\n  mutate(weight.kg = weight / 2.2) %>%\n  filter(!is.na(fAge)) %>%\n  ggplot(aes(x = fAge, y = weight.kg)) + \n    geom_point() + \n    labs(x = \"Father's Age (years)\", y = \"Birth Weight (kg)\")\n\n\n\n\nIn the example above, we feed the data frame into the mutate function. mutate expects a data frame as a first argument, and subsequent arguments specify the new variables to be created. births %>% mutate(weight.kg = weight / 2.2) is thus equivalent to mutate(births, weight.kg = weight / 2.2)). We then pipe the output to filter, removing NA fathers, and then pipe that output as the input to ggplot.\nAs mentioned previously, it’s good coding style to write each discrete step as its own line when using piping. This make it easier to understand what the steps of the analysis are as well as facilitating changes to the code (commenting out lines, adding lines, etc)\n\n\n5.6.5 Assigning the output of a statement involving pipes to a variable\nIt’s important to recognize that pipes are simply a convenient way to chain together a series of expression. Just like any other compound expression, the output of a series of pipe statements can be assigned to a variable, like so:\n\nstats.old.moms <-\n  births %>%\n  filter(mAge > 35) %>%\n  summarize(median.gestation = median(weeks), \n            mean.weight = mean(weight))\n\nstats.old.moms\n\n# A tibble: 1 × 2\n  median.gestation mean.weight\n             <dbl>       <dbl>\n1               38        6.94\n\n\nNote that our summary table, stats.old.moms, is itself a data frame.\n\n\n5.6.6 Compound assignment pipe operator\nA fairly common operation when working interactively in R is to update an existing data frame. magrittr defines another pipe operator – %<>% – called the “compound assignment” pipe operator, to facilitate this. The compound assignment pipe operator has the basic usage lhs %<>% rhs. This operator evaluates the function on the rhs using the lhs as the first argument, and then updates the lhs with the resulting value. This is simply shorthand for writing lhs <- lhs %>% rhs.\n\nstats.old.moms %<>%  # note compound pipe operator!\n  mutate(mean.weight.kg = mean.weight / 2.2)\n\n\n\n5.6.7 The dot operator with pipes\nWhen working with pipes, sometimes you’ll want to use the lhs in multiple places on the rhs, or as something other than the first argument to the rhs. magrittr provides for this situation by using the dot (.) operator as a placeholder. Using the dot operator, the expression y %>% f(x, .) is equivalent to f(x,y).\n\nc(\"dog\", \"cakes\", \"sauce\", \"house\") %>%  # create a vector\n  sample(1) %>% # pick a random single element of that vector\n  str_c(\"hot\", .)  # string concatenate the pick with the word \"hot\"\n\n[1] \"hotsauce\"\n\n\n\n\n5.6.8 The exposition pipe operator\nmagrittr defines another operator called the “exposition pipe operator”, designed %$%. This operator exposes the names in the lhs to the expression on the rhs.\nHere is an example of using the exposition pipe operator to simply return the vector of weights:\n\nbirths %>%\n  filter(premature == \"premie\") %$%  # note the different pipe operator!\n  weight\n\n [1] 1.63 5.50 2.69 6.50 7.81 4.75 3.75 2.19 6.81 4.69 6.75 4.50 5.94 4.50 5.06\n[16] 5.69 1.69 6.31 2.63 5.88 3.63\n\n\nIf we wanted to calculate the minimum and maximum weight of premature babies in the data set we could do the following (though I’d usually prefer summarize() unless I needed the results in the form of a vector):\n\nbirths %>%\n  filter(mAge > 35) %$%  # note the different pipe operator!\n  c(min(weight), max(weight)) \n\n[1]  2.19 10.13"
  },
  {
    "objectID": "R/R-ggplot-intro.html#loading-ggplot2",
    "href": "R/R-ggplot-intro.html#loading-ggplot2",
    "title": "6  Introduction to ggplot2",
    "section": "6.1 Loading ggplot2",
    "text": "6.1 Loading ggplot2\nggplot2 is one of the packages included in the tidyverse meta-package we installed during the previous class session (see the previous lecture notes for instruction if you have not installed tidyverse). If we load the tidyverse package, ggplot2 is automatically loaded as well.\n\nlibrary(tidyverse)\n\nHowever if we wanted to we could load only ggplot2 as follows:\n\nlibrary(ggplot2)  # not necessary if we already loaded tidyverse"
  },
  {
    "objectID": "R/R-ggplot-intro.html#example-data-set-andersons-iris-data",
    "href": "R/R-ggplot-intro.html#example-data-set-andersons-iris-data",
    "title": "6  Introduction to ggplot2",
    "section": "6.2 Example data set: Anderson’s Iris Data",
    "text": "6.2 Example data set: Anderson’s Iris Data\nTo illustrate ggplot2 we’ll use a dataset called iris. This data set was made famous by the statistician and geneticist R. A. Fisher who used it to illustrate many of the fundamental statistical methods he developed (Recall that Fisher was one of the key contributors to the modern synthesis in biology, reconciling evolution and genetics in the early 20th century). The data set consists of four morphometric measurements for specimens from three different iris species (Iris setosa, I. versicolor, and I. virginica). Use the R help to read about the iris data set (?iris). We’ll be using this data set repeatedly in future weeks so familiarize yourself with it.\nThe iris data is included in a standard R package (datasets) that is made available automatically when you start up R. As a consequence we don’t need to explicitly load the iris data from a file. Let’s take a few minutes to explore this iris data set before we start generating plots:\n\nnames(iris) # get the variable names in the dataset\n\n[1] \"Sepal.Length\" \"Sepal.Width\"  \"Petal.Length\" \"Petal.Width\"  \"Species\"     \n\ndim(iris)   # dimensions given as rows, columns\n\n[1] 150   5\n\nhead(iris)  # can you figure out what the head function does?\n\n  Sepal.Length Sepal.Width Petal.Length Petal.Width Species\n1          5.1         3.5          1.4         0.2  setosa\n2          4.9         3.0          1.4         0.2  setosa\n3          4.7         3.2          1.3         0.2  setosa\n4          4.6         3.1          1.5         0.2  setosa\n5          5.0         3.6          1.4         0.2  setosa\n6          5.4         3.9          1.7         0.4  setosa\n\ntail(iris)  # what about the tail function?\n\n    Sepal.Length Sepal.Width Petal.Length Petal.Width   Species\n145          6.7         3.3          5.7         2.5 virginica\n146          6.7         3.0          5.2         2.3 virginica\n147          6.3         2.5          5.0         1.9 virginica\n148          6.5         3.0          5.2         2.0 virginica\n149          6.2         3.4          5.4         2.3 virginica\n150          5.9         3.0          5.1         1.8 virginica"
  },
  {
    "objectID": "R/R-ggplot-intro.html#template-for-single-layer-plots-in-ggplot2",
    "href": "R/R-ggplot-intro.html#template-for-single-layer-plots-in-ggplot2",
    "title": "6  Introduction to ggplot2",
    "section": "6.3 Template for single layer plots in ggplot2",
    "text": "6.3 Template for single layer plots in ggplot2\nA basic template for building a single layer plot using ggplot2 is shown below. When creating a plot, you need to replace the text in brackets (e.g. <DATA>) with appropriate objects, functions, or arguments:\n# NOTE: this is pseudo-code. It will not run!\n\nggplot(data = <DATA>) + \n  <GEOM_FUNCTION>(mapping = aes(<MAPPINGS>))\nThe base function ggplot() is responsible for creating the coordinate system in which the plot will be display. To this coordinate system we add a geometric mapping (called a “geom” for short) that specifies how data gets mapped into the coordinate system (e.g. points, bars, etc). Included as an input to the geom function is the aesthetic mapping function that specifies which variables to use in the geometric mapping (e.g. which variables to treat as the x- and y-coordinates), colors, etc.\nFor example, using this template we can create a scatter plot that show the relationship between the variables Sepal.Width and Petal.Width. To do so we subsitute iris for <DATA>, geom_point for <GEOM_FUNCTION>, and x = Sepal.Width and y = Petal.Width for <MAPPINGS>.\n\nggplot(data = iris) +\n  geom_point(mapping = aes(x = Sepal.Width,  y = Petal.Width))\n\n\n\n\nIf we were to translate this code block to English, we might write it as “Using the iris data frame as the source of data, create a point plot using each observeration’s Sepal.Width variable for the x-coordinate and the Petal.Width variable for the y-coordinate.”"
  },
  {
    "objectID": "R/R-ggplot-intro.html#an-aside-about-function-arguments",
    "href": "R/R-ggplot-intro.html#an-aside-about-function-arguments",
    "title": "6  Introduction to ggplot2",
    "section": "6.4 An aside about function arguments",
    "text": "6.4 An aside about function arguments\nThe inputs to a function are also known as “arguments”. In R, when you call a function you can specify the arguments by keyword (i.e. using names specified in the function definition) or by position (i.e. the order of the inputs).\nIn our bar plot above, we’re using using keyword arguments. For example, in the line ggplot(data = iris), iris is treated as the “data” argument. Similarly, in the second line, aes(x = Sepal.Width, y = Petal.Width) is the “mapping” argument to geom_bar. Note that aes is itself a function (see ?aes) that takes arguments that can be specified positionally or with keywords.\nIf we wanted to, we could instead use position arguments when calling a function, by passing inputs to the function corresponding to the order they are specified in the function definition. For example, take a minute to read the documentation for the ggplot function (?ggplot). Near the top of the help page you’ll see a description of how the function is called under “Usage”. Reading the Usage section you’ll see that the the “data” argument is the first positional argument to ggplot. Similarly, if you read the docs for the geom_point function you’ll see that mapping is the first positional argument for that function.\nThe equivalent of our previous example, but now using positional arguments is:\n\nggplot(iris) +   # note we dropped the \"data = \" part\n  # note we dropped the \"mapping = \" part from the geom_point call\n  geom_point(aes(x = Sepal.Width,  y = Petal.Width))\n\n\n\n\nThe upside of using positional arguments is that it means less typing, which is useful when working interactively at the console (or in an R Notebok). The downside to using positional arguments is you need to remember or lookup the order of the arguments. Using positional arguments can also make your code less “self documenting” in the sense that it is less explicit about how the inputs are being treated. While the argument “x” is the first argument to the aes function, I chose to explicitly include the argument name to make it clear what variable I’m plotting on the x-axis.\nWe will cover function arguments in greater detail a class session or two from now, when we learn how to write our own functions."
  },
  {
    "objectID": "R/R-ggplot-intro.html#strip-plots",
    "href": "R/R-ggplot-intro.html#strip-plots",
    "title": "6  Introduction to ggplot2",
    "section": "6.5 Strip plots",
    "text": "6.5 Strip plots\nOne of the simplest visualizations of a continuous variable is to draw points along a number line, where each point represent the value of one of the observations. This is sometimes called a “strip plot”.\nFirst, we’ll use the geom_point function as shown below to generate a strip plot for the Sepal.Width variable in the iris data set.\n\nggplot(data = iris) + \n  geom_point(aes(x = Sepal.Width, y = 0))\n\n\n\n\n\n6.5.1 Jittering data\nThere should have been 150 points plotted in the figure above (one for each of the iris plants in the data set), but visually it looks like only about 25 or 30 points are shown. What’s going on? If you examine the iris data, you’ll see that the all the measures are rounded to the nearest tenth of a centimer, so that there are a large number of observations with identical values of Sepal.Width. This is a limitation of the precision of measurements that was used when generating the data set.\nTo provide a visual clue that there are multiple observations that share the same value, we can slightly “jitter” the values (randomly move points a small amount in either in the vertical or horizontal direction). Jittering is used solely to enhance visualization, and any statistical analyses you carry out would be based on the original data. When presenting your data to someone else, should note when you’ve used jittering so as not to misconvey the actual data.\nJittering can be accomplished using geom_jitter, which is derived from geom_point:\n\nggplot(data = iris) + \n  geom_jitter(aes(x = Sepal.Width, y = 0), \n              width = 0.05, height = 0, alpha = 0.25)\n\n\n\n\nThe width and height arguments specify the maximum amount (as fractions of the data) to jitter the observed data points in the horizontal (width) and vertical (height) directions. Here we only jitter the data in the horizontal direction. The alpha argument controls the transparency of the points – the valid range of alpha values is 0 to 1, where 0 means completely transparent and 1 is completely opaque.\nWithin a geom, arguments outside of the aes mapping apply uniformly across the visualization (i.e. they are fixed values). For example, setting `alpha = 0.25’ made all the points transparent.\n\n\n6.5.2 Adding categorical information\nRecall that are three different species represented in the data: Iris setosa, I. versicolor, and I. virginica. Let’s see how to generate a strip plot that also includes a breakdown by species.\n\nggplot(data = iris) + \n  geom_jitter(aes(x = Sepal.Width, y = Species),\n              width=0.05, height=0.1, alpha=0.5)\n\n\n\n\nThat was easy! All we had to do was change the aesthetic mapping in geom_jitter, specifying “Species” as the y variable. I also added a little vertical jitter as well to better separate the points.\nNow we have a much better sense of the data. In particular it’s clear that the I. setosa specimens generally have wider sepals than samples from the other two species.\nLet’s tweak this a little by also adding color information, to further emphasize the distinct groupings. We can do this by adding another argument to the aesthetic mapping in geom_jitter.\n\nggplot(data = iris) + \n  geom_jitter(aes(x = Sepal.Width, y = Species, color=Species),\n              width=0.05, height=0.1, alpha=0.5)\n\n\n\n\n\n\n6.5.3 Rotating plot coordinates\nWhat if we wanted to rotate this plot 90 degrees, depicting species on the x-axis and sepal width on the y-axis. For this example, it would be easy to do this by simpling swapping the variables in the aes mapping argument. However an alternate way to do this is with a coordinate transformation function. Here we use coord_flip to flip the x- and y-axes:\n\nggplot(data = iris) + \n  geom_jitter(aes(x = Sepal.Width, y = Species, color=Species),\n              width=0.05, height=0.1, alpha=0.5) +\n  coord_flip()\n\n\n\n\nWe’ll see other uses of coordinate transformations in later lectures."
  },
  {
    "objectID": "R/R-ggplot-intro.html#histograms",
    "href": "R/R-ggplot-intro.html#histograms",
    "title": "6  Introduction to ggplot2",
    "section": "6.6 Histograms",
    "text": "6.6 Histograms\nHistograms are probably the most common way to depict univariate data. In a histogram rather than showing individual observations, we divide the range of the data into a set of bins, and use vertical bars to depict the number (frequency) of observations that fall into each bin. This gives a good sense of the intervals in which most of the observations are found.\nThe geom, geom_histogram, takes care of both the geometric representation and the statistical transformations of the data necessary to calculate the counts in each binn.\nHere’s the simplest way to use geom_histogram:\n\nggplot(iris) + \n  geom_histogram(aes(x = Sepal.Width))\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\nThe default number of bins that geom_histogram uses is 30. For modest size data sets this is often too many bins, so it’s worth exploring how the histogram changes with different bin numbers:\n\nggplot(iris) + \n  geom_histogram(aes(x = Sepal.Width), bins = 10)\n\n\n\n\n\nggplot(iris) + \n  geom_histogram(aes(x = Sepal.Width), bins = 12)\n\n\n\n\nOne important thing to note when looking at these histograms with different numbers of bins is that the number of bins used can change your perception of the data. For example, the number of peaks (modes) in the data can be very sensitive to the bin number as can the perception of gaps.\n\n6.6.1 Variations on histograms when considering categorical data\nAs before, we probably want to break the data down by species. Here we’re faced with some choices about how we depict that data. Do we generate a “stacked histogram” to where the colors indicate the number of observations in each bin that belong to each species? Do we generate side-by-side bars for each species? Or Do we generate separate histograms for each species, and show them overlapping?\nStacked histograms are the default if we associate a categorical variable with the bar fill color:\n\nggplot(iris) + \n  geom_histogram(aes(x = Sepal.Width, fill = Species), \n                 bins = 12)\n\n\n\n\nTo get side-by-side bars, specify “dodge” as the position argument to geom_histogram.\n\nggplot(iris) + \n  geom_histogram(aes(x = Sepal.Width, fill = Species),\n                 bins = 12, position = \"dodge\")\n\n\n\n\nIf you want overlapping histograms, use position = \"identity\" instead. When generating overlapping histograms like this, you probably want to make the bars semi-transparent so you can can distinguish the overlapping data.\n\nggplot(iris) + \n  geom_histogram(aes(x = Sepal.Width, fill = Species), \n                 bins = 12, position = \"identity\", alpha = 0.4)"
  },
  {
    "objectID": "R/R-ggplot-intro.html#faceting-to-depict-categorical-information",
    "href": "R/R-ggplot-intro.html#faceting-to-depict-categorical-information",
    "title": "6  Introduction to ggplot2",
    "section": "6.7 Faceting to depict categorical information",
    "text": "6.7 Faceting to depict categorical information\nYet another way to represent the histograms for the three species is to using faceting, the create subplots for each species. Faceting is the operation of subsetting the data with respect to a discrete or categorical variable of interest, and generating the same plot type for each subset. Here we use the “ncol” argument to the facet_wrap function to specify that the subplots should be drawn in a single vertical column to facilitate comparison of the distributions.\n\nggplot(iris) + \n  geom_histogram(aes(x = Sepal.Width, fill = Species), bins = 12) + \n  facet_wrap(~Species, ncol = 1)"
  },
  {
    "objectID": "R/R-ggplot-intro.html#density-plots",
    "href": "R/R-ggplot-intro.html#density-plots",
    "title": "6  Introduction to ggplot2",
    "section": "6.8 Density plots",
    "text": "6.8 Density plots\nOne shortcoming of histograms is that they are sensitive to the choice of bin margins and the number of bins. An alternative is a “density plot”, which you can think of as a smoothed version of a histogram.\n\nggplot(iris) + \n  geom_density(aes(x = Sepal.Width, fill = Species), alpha=0.25)\n\n\n\n\nDensity plots still make some assumptions that affect the visualization, in particular a “smoothing bandwidth” (specified by the argument bw) which determines how course or granular the density estimation is.\nNote that the vertical scale on a density plot is no longer counts (frequency) but probability density. In a density plot, the total area under the plot adds up to one. Intervals in a density plot therefore have a probabilistic intepretation."
  },
  {
    "objectID": "R/R-ggplot-intro.html#violin-or-beanplot",
    "href": "R/R-ggplot-intro.html#violin-or-beanplot",
    "title": "6  Introduction to ggplot2",
    "section": "6.9 Violin or Beanplot",
    "text": "6.9 Violin or Beanplot\nA violin plot (sometimes called a bean plot) is closely related to a density plot. In fact you can think of a violin plot as a density plot rotated 90 degress and mirrored left/right.\n\nggplot(iris) + \n  geom_violin(aes(x = Species, y = Sepal.Width, color = Species, fill=Species), \n              alpha = 0.25)"
  },
  {
    "objectID": "R/R-ggplot-intro.html#boxplots",
    "href": "R/R-ggplot-intro.html#boxplots",
    "title": "6  Introduction to ggplot2",
    "section": "6.10 Boxplots",
    "text": "6.10 Boxplots\nBoxplots are another frequently used univariate visualization. Boxplots provide a compact summary of single variables, and are most often used for comparing distributions between groups.\nA standard box plot depicts five useful features of a set of observations: 1) the median (center most line); 2 and 3) the first and third quartiles (top and bottom of the box); 4) the whiskers of a boxplot extend from the first/third quartile to the highest value that is within 1.5 * IQR, where IQR is the inter-quartile range (distance between the first and third quartiles); 5) points outside of the whiskers are usually consider extremal points or outliers. There are many variants on box plots, particularly with respect to the “whiskers”. It’s always a good idea to be explicit about what a box plot you’ve created shows.\n\nggplot(iris) + \n  geom_boxplot(aes(x = Species, y = Sepal.Width, color = Species))\n\n\n\n\nBoxplots are most commonly drawn with the cateogorical variable on the x-axis."
  },
  {
    "objectID": "R/R-ggplot-intro.html#building-complex-visualizations-with-layers",
    "href": "R/R-ggplot-intro.html#building-complex-visualizations-with-layers",
    "title": "6  Introduction to ggplot2",
    "section": "6.11 Building complex visualizations with layers",
    "text": "6.11 Building complex visualizations with layers\nAll of our ggplot2 examples up to now have involved a single geom. We can think of geoms as “layers” of information in a plot. One of the powerful features of plotting useing ggplot2 is that it is trivial to combine layers to make more complex plots.\nThe template for multi-layered plots is a simple extension of the single layer:\nggplot(data = <DATA>) + \n  <GEOM_FUNCTION1>(mapping = aes(<MAPPINGS>)) + \n  <GEOM_FUNCTION2>(mapping = aes(<MAPPINGS>))"
  },
  {
    "objectID": "R/R-ggplot-intro.html#useful-combination-plots",
    "href": "R/R-ggplot-intro.html#useful-combination-plots",
    "title": "6  Introduction to ggplot2",
    "section": "6.12 Useful combination plots",
    "text": "6.12 Useful combination plots\nBoxplot or violin plots represent visual summaries/simplifications of the underlying data. This is useful but sometimes key information is lost in the process of summarizing. Combining these plots with a strip plot give you both the “birds eye view” as well as granular information.\n\n6.12.1 Boxplot plus strip plot\nHere’s an example of combining box plots and strip plots:\n\nggplot(iris) +\n  # outlier.shape = NA suppresses the depiction of outlier points in the boxplot\n  geom_boxplot(aes(x = Species, y = Sepal.Width), outlier.shape = NA) + \n  # size sets the point size for the jitter plot\n  geom_jitter(aes(x = Species, y = Sepal.Width), width=0.2, height=0.05, alpha=0.35, size=0.75)\n\n\n\n\nNote that I suppressed the plotting of outliers in geom_boxplot so as not to draw the same points twice (the individual data are drawn by geom_jitter).\n\n\n6.12.2 Setting shared aesthetics\nThe example above works well, but you might have noticed that there’s some repetition of code. In particular, we set the same aesthetic mapping in both geom_boxplot and geom_jitter. It turns out that creating layers that share some of the same aesthetic values is a common case. To deal with such cases, you can specify shared aesthetic mappings as an argument to the ggplot function and then set additional aesthetics specific to each layer in the individual geoms. Using this approach, our previous example can be written more compactly as follow.\n\nggplot(iris, mapping = aes(x = Species, y = Sepal.Width)) +\n  geom_boxplot(outlier.shape = NA) + \n  # note how we specify a layer specific aesthetic in geom_jitter\n  geom_jitter(aes(color = Species), width=0.2, height=0.05, alpha=0.5, size=0.75)"
  },
  {
    "objectID": "R/R-ggplot-intro.html#ggplot-layers-can-be-assigned-to-variables",
    "href": "R/R-ggplot-intro.html#ggplot-layers-can-be-assigned-to-variables",
    "title": "6  Introduction to ggplot2",
    "section": "6.13 ggplot layers can be assigned to variables",
    "text": "6.13 ggplot layers can be assigned to variables\nThe function ggplot() returns a “plot object” that we can assign to a variable. The following example illustrates this:\n\n# create base plot object and assign to variable p\n# this does NOT draw the plot\np <- ggplot(iris, mapping = aes(x = Species, y = Sepal.Width))   \n\nIn the code above we created a plot object and assigned it to the variable p. However, the plot wasn’t drawn. To draw the plot object we evaluate it as so:\n\np  # try to draw the plot object\n\n\n\n\nThe code block above didn’t generate an image, because we haven’t added a geom to the plot to determine how our data should be drawn. We can add a geom to our pre-created plot object as so:\n\n# add a point geom to our base layer and draw the plot\np + geom_boxplot()\n\n\n\n\nIf we wanted to we could have assigned the geom to a variable as well:\n\nbox.layer <- geom_boxplot()\np + box.layer\n\n\n\n\nIn this case we don’t really gain anything by creating an intermediate variable, but for more complex plots or when considering different versions of a plot this can be very useful.\n\n6.13.1 Violin plot plus strip plot\nHere is the principle of combining layers, applied to a combined violin plot + strip plot. Again, we set shared aesthetic mappings in ggplot function call and this time we assign individual layers of the plot to variables.\n\np <- ggplot(iris, mapping = aes(x = Species, y = Sepal.Width, color = Species))\n\nviolin.layer <- geom_violin()\njitter.layer <- geom_jitter(width=0.15, height=0.05, alpha=0.5, size=0.75)\n\np + violin.layer + jitter.layer # combined layers of plot and draw"
  },
  {
    "objectID": "R/R-ggplot-intro.html#adding-titles-and-tweaking-axis-labels",
    "href": "R/R-ggplot-intro.html#adding-titles-and-tweaking-axis-labels",
    "title": "6  Introduction to ggplot2",
    "section": "6.14 Adding titles and tweaking axis labels",
    "text": "6.14 Adding titles and tweaking axis labels\nggplot2 automatically adds axis labels based on the variable names in the data frame passed to ggplot. Sometimes these are appropriate, but more presentable figures you’ll usually want to tweak the axis labs (e.g. adding units). The labs (short for labels) function allows you to do so, and also let’s you set a title for your plot. We’ll illustrate this by modifying our previous figure. Note that we save considerable amounts of re-typing since we had already assigned three of the plot layers to variables in the previous code block:\n\np + violin.layer + jitter.layer + \n  labs(x = \"Species\", y = \"Sepal Width (cm)\", \n       title = \"Sepal Width Distributions for Three Iris Species\")"
  },
  {
    "objectID": "R/R-ggplot-intro.html#ggplot2-themes",
    "href": "R/R-ggplot-intro.html#ggplot2-themes",
    "title": "6  Introduction to ggplot2",
    "section": "6.15 ggplot2 themes",
    "text": "6.15 ggplot2 themes\nBy now you’re probably familiar with the default “look” of plots generated by ggplot2, in particular the ubiquitous gray background with a white grid. This default works fairly well in the context of RStudio notebooks and HTML output, but might not work as well for a published figure or a slide presentation. Almost every individual aspect of a plot can be tweaked, but ggplot2 provides an easier way to make consistent changes to a plot using “themes”. You can think of a theme as adding another layer to your plot. Themes should generally be applied after all the other graphical layers are created (geoms, facets, labels) so the changes they create affect all the prior layers.\nThere are eight default themes included with ggplot2, which can be invoked by calling the corresponding theme functions: theme_gray, theme_bw, theme_linedraw, theme_light, theme_dark, theme_minimal, theme_classic, and theme_void (See http://ggplot2.tidyverse.org/reference/ggtheme.html for a visual tour of all the default themes)\nFor example, let’s generate a boxplot using theme_bw which get’s rid of the gray background:\n\n# create another variable to hold combination of three previous \n# ggplot layers. I'm doing this because I'm going to keep re-using\n# the same plot in the following code blocks\nviolin.plus.jitter <- p + violin.layer + jitter.layer\n\nviolin.plus.jitter + theme_bw()\n\n\n\n\nAnother theme, theme_classic, remove the grid lines completely, and also gets rid of the top-most and right-most axis lines.\n\nviolin.plus.jitter + theme_classic()\n\n\n\n\n\n6.15.1 Further customization with ggplot2::theme\nIn addition to the eight complete themes, there is a theme function in ggplot2 that allows you to tweak particular elements of a theme (see ?theme for all the possible options). For example, to tweak just the aspect ratio of a plot (the ratio of width to height), you can set the aspect.ratio argument in theme:\n\nviolin.plus.jitter + theme_classic() + theme(aspect.ratio = 1)\n\n\n\n\nTheme related function calls can be combined to generate new themes. For example, let’s create a theme called my.theme by combining theme_classic with a call to theme:\n\nmy.theme <- theme_classic()  + theme(aspect.ratio = 1)\n\nWe can then apply this theme as so:\n\nviolin.plus.jitter + my.theme"
  },
  {
    "objectID": "R/R-ggplot-intro.html#other-aspects-of-ggplots-can-be-assigned-to-variables",
    "href": "R/R-ggplot-intro.html#other-aspects-of-ggplots-can-be-assigned-to-variables",
    "title": "6  Introduction to ggplot2",
    "section": "6.16 Other aspects of ggplots can be assigned to variables",
    "text": "6.16 Other aspects of ggplots can be assigned to variables\nPlot objects, geoms and themes are not the only aspects of a figure that can be assigned to variables for later use. For example, we can create a label object:\n\nmy.labels <- labs(x = \"Species\", y = \"Sepal Width (cm)\", \n                  title = \"Sepal Width Distributions for Three Iris Species\")\n\nCombining all of our variables as so, we generate our new plot:\n\nviolin.plus.jitter + my.labels + my.theme"
  },
  {
    "objectID": "R/R-ggplot-intro.html#bivariate-plots",
    "href": "R/R-ggplot-intro.html#bivariate-plots",
    "title": "6  Introduction to ggplot2",
    "section": "6.17 Bivariate plots",
    "text": "6.17 Bivariate plots\nNow we turn our attention to some useful representations of bivariate distributions.\nFor the purposes of these illustrations I’m initially going to restrict my attention to just one of the three species represented in the iris data set – the I. setosa specimens. This allows us to introduce a vary useful base function called subset(). subset() will return subsets of a vector or data frames that meets the specified conditions. This can also be accomplished with conditional indexing but subset() is usually less verbose.\n\n# create a new data frame composed only of the I. setosa samples\nsetosa.only <- subset(iris, Species == \"setosa\")\n\nIn the examples that follow, I’m going to illustrate different ways of representing the same bivariate distribution – the joint distribution of Sepal Length and Sepal Width – over and over again. To avoid repitition, let’s assign the base ggplot layer to a variable as we did in our previous examples. We’ll also pre-create a label layer.\n\nsetosa.sepals <- ggplot(setosa.only, \n                        mapping = aes(x = Sepal.Length, y = Sepal.Width))\n\nsepal.labels <- labs(x = \"Sepal Length (cm)\", y = \"Sepal Width (cm)\",\n                     title = \"Relationship between Sepal Length and Width\",\n                     caption = \"data from Anderson (1935)\")\n\n\n6.17.1 Scatter plots\nA scatter plot is one of the simplest representations of a bivariate distribution. Scatter plots are simple to create in ggplot2 by specifying the appropriate X and Y variables in the aesthetic mapping and using geom_point for the geometric mapping.\n\nsetosa.sepals  + geom_point() + sepal.labels\n\n\n\n\n\n\n6.17.2 Adding a trend line to a scatter plot\nggplot2 makes it easy to add trend lines to plots. I use “trend lines” here to refer to representations like regression lines, smoothing splines, or other representations mean to help visualize the relationship between pairs of variables. We’ll spend a fair amount of time exploring the mathematics and interpetation of regression lines and related techniques in later lectures, but for now just think about trends lines as summary representations for bivariate relationships.\nTrend lines can be created using geom_smooth. Let’s add a default trend line to our I. setosa scatter plot of the Sepal Width vs Sepal Length:\n\nsetosa.sepals + \n  geom_jitter() +  # using geom_jitter to avoid overplotting of points\n  geom_smooth() +\n  sepal.labels + labs(subtitle = \"I. setosa data only\") +\n  my.theme\n\n`geom_smooth()` using method = 'loess' and formula = 'y ~ x'\n\n\n\n\n\nThe defaul trend line that geom_smooth fits is generated by a technique called “LOESS regression”. LOESS regression is a non-linear curve fitting method, hence the squiggly trend line we see above. The smoothness of the LOESS regression is controlled by a parameter called span which is related to the proportion of points used. We’ll discuss LOESS in detail in a later lecture, but here’s an illustration how changing the span affects the smoothness of the fit curve:\n\nsetosa.sepals + \n  geom_jitter() +  # using geom_jitter to avoid overplotting of points\n  geom_smooth(span = 0.95) +\n  sepal.labels + labs(subtitle = \"I. setosa data only\") +\n  my.theme\n\n`geom_smooth()` using method = 'loess' and formula = 'y ~ x'\n\n\n\n\n\n\n6.17.2.1 Linear trend lines\nIf instead we want a straight trend line, as would typically be depicted for a linear regression model we can specify a different statistical method:\n\nsetosa.sepals + \n  geom_jitter() +  # using geom_jitter to avoid overplotting of points\n  geom_smooth(method = \"lm\", color = \"red\") + # using linear model (\"lm\")\n  sepal.labels + labs(subtitle = \"I. setosa data only\") +\n  my.theme\n\n`geom_smooth()` using formula = 'y ~ x'"
  },
  {
    "objectID": "R/R-ggplot-intro.html#bivariate-density-plots",
    "href": "R/R-ggplot-intro.html#bivariate-density-plots",
    "title": "6  Introduction to ggplot2",
    "section": "6.18 Bivariate density plots",
    "text": "6.18 Bivariate density plots\nThe density plot, which we introduced as a visualization for univariate data, can be extended to two-dimensional data. In a one dimensional density plot, the height of the curve was related to the relatively density of points in the surrounding region. In a 2D density plot, nested contours (or contours plus colors) indicate regions of higher local density. Let’s illustrate this with an example:\n\nsetosa.sepals + \n  geom_density2d() + \n  sepal.labels + labs(subtitle = \"I. setosa data only\") +\n  my.theme\n\n\n\n\nThe relationship between the 2D density plot and a scatter plot can be made clearer if we combine the two:\n\nsetosa.sepals + \n  geom_density_2d() + \n  geom_jitter(alpha=0.35) +\n  sepal.labels + labs(subtitle = \"I. setosa data only\") +\n  my.theme"
  },
  {
    "objectID": "R/R-ggplot-intro.html#combining-scatter-plots-and-density-plots-with-categorical-information",
    "href": "R/R-ggplot-intro.html#combining-scatter-plots-and-density-plots-with-categorical-information",
    "title": "6  Introduction to ggplot2",
    "section": "6.19 Combining Scatter Plots and Density Plots with Categorical Information",
    "text": "6.19 Combining Scatter Plots and Density Plots with Categorical Information\nAs with many of the univariate visualizations we explored, it is often useful to depict bivariate relationships as we change a categorical variable. To illustrate this, we’ll go back to using the full iris data set.\n\nall.sepals <- ggplot(iris, aes(x = Sepal.Length, y = Sepal.Width))\n\nall.sepals + \n  geom_point(aes(color = Species, shape = Species), size = 2, alpha = 0.6) +\n  sepal.labels + labs(subtitle = \"All species\") +\n  my.theme\n\n\n\n\nNotice how in our aesthetic mapping we specified that both color and shape should be used to represent the species categories.\nThe same thing can be accomplished with a 2D density plot.\n\nall.sepals + \n  geom_density_2d(aes(color = Species)) +\n  sepal.labels + labs(subtitle = \"All species\") +\n  my.theme\n\n\n\n\nAs you can see, in the density plots above, when you have multiple categorical variables and there is significant overlap in the range of each sub-distribution, figures can become quite busy. As we’ve seen previously, faceting (conditioning) can be a good way to deal with this. Below a combination of scatter plots and 2D density plots, combined with faceting on the species variable.\n\nall.sepals + \n  geom_density_2d(aes(color = Species), alpha = 0.5) + \n  geom_point(aes(color = Species), alpha=0.5, size=1) + \n  facet_wrap(~ Species) +\n  sepal.labels + labs(subtitle = \"All species\") +\n  theme_bw() + \n  theme(aspect.ratio = 1, legend.position = \"none\")  # get rid of legend\n\n\n\n\nIn this example I went back to using a theme that includes grid lines to facilitate more accurate comparisons of the distributions across the facets. I also got rid of the legend, because the information there was redundant."
  },
  {
    "objectID": "R/R-ggplot-intro.html#density-plots-with-fill",
    "href": "R/R-ggplot-intro.html#density-plots-with-fill",
    "title": "6  Introduction to ggplot2",
    "section": "6.20 Density plots with fill",
    "text": "6.20 Density plots with fill\nLet’s revisit our earlier single species 2D density plot. Instead of simply drawing contour lines, let’s use color information to help guide the eye to areas of higher density. To draw filled contours, we use a sister function to geom_density_2d called stat_density_2d:\n\nsetosa.sepals + \n  stat_density_2d(aes(fill = ..level..), geom = \"polygon\") + \n  sepal.labels + labs(subtitle = \"I. setosa data only\") +\n  my.theme\n\nWarning: The dot-dot notation (`..level..`) was deprecated in ggplot2 3.4.0.\nℹ Please use `after_stat(level)` instead.\n\n\n\n\n\nUsing the default color scale, areas of low density are drawn in dark blue, whereas areas of high density are drawn in light blue. I personally find this dark -to-light color scale non-intuitive for density data, and would prefer that darker regions indicate area of higher density. If we want to change the color scale, we can use the a scale function (in this case scale_fill_continuous) to set the color values used for the low and high values (this function we’ll interpolate the intervening values for us).\nNOTE: when specifying color names, R accepts standard HTML color names (see the Wikipedia page on web colors for a list). We’ll also see other ways to set color values in a later class session.\n\nsetosa.sepals + \n  stat_density_2d(aes(fill = ..level..), geom = \"polygon\") + \n  # lavenderblush is the HTML standard name for a light purplish-pink color\n  scale_fill_continuous(low=\"lavenderblush\", high=\"red\") +\n  sepal.labels + labs(subtitle = \"I. setosa data only\") +\n  my.theme\n\n\n\n\nThe two contour plots we generated looked a little funny because the contours are cutoff due to the contour regions being outside the limits of the plot. To fix this, we can change the plot limits using the lims function as shown in the following code block. We’ll also add the scatter (jittered) to the emphasize the relationship between the levels, and we’ll change the title for the color legend on the right by specifying a text label associated with the fill arguments in the labs function.\n\nsetosa.sepals + \n  stat_density_2d(aes(fill = ..level..), geom = \"polygon\") +\n  scale_fill_continuous(low=\"lavenderblush\", high=\"red\") +\n  geom_jitter(alpha=0.5, size = 1.1) +\n  \n  # customize labels, including legend label for fill\n  labs(x = \"Sepal Length(cm)\", y = \"Sepal Width (cm)\",\n       title = \"Relationship between sepal length and width\",\n       subtitle = \"I. setosa specimens only\",\n       fill = \"Density\") +\n  \n  # Set plot limits\n  lims(x = c(4,6), y = c(2.5, 4.5)) +\n  my.theme"
  },
  {
    "objectID": "R/R-ggplot-intro.html#d-bin-and-hex-plots",
    "href": "R/R-ggplot-intro.html#d-bin-and-hex-plots",
    "title": "6  Introduction to ggplot2",
    "section": "6.21 2D bin and hex plots",
    "text": "6.21 2D bin and hex plots\nTwo dimensional bin and hex plots are alterative ways to represent the joint density of points in the Cartesian plane. Here are examples of to generate these plot types. Compare them to our previous examples.\nA 2D bin plot can be tought of as a 2D histogram:\n\nsetosa.sepals + \n  geom_bin2d(binwidth = 0.2) + \n  scale_fill_continuous(low=\"lavenderblush\", high=\"red\") +\n  sepal.labels + labs(subtitle = \"I. setosa data only\") +\n  my.theme\n\n\n\n\nA hex plot is similar to a 2D bin plot but uses hexagonal regions instead of squares. Hexagonal bins are useful because they can avoid visual artefacts sometimes apparent with square bins:\n\nsetosa.sepals + \n  geom_hex(binwidth = 0.2) + \n  scale_fill_continuous(low=\"lavenderblush\", high=\"red\") +\n  sepal.labels + labs(subtitle = \"I. setosa data only\") +\n  my.theme\n\nWarning: Computation failed in `stat_binhex()`\nCaused by error in `compute_group()`:\n! The package `hexbin` is required for `stat_binhex()`"
  },
  {
    "objectID": "R/R-ggplot-intro.html#the-cowplot-package",
    "href": "R/R-ggplot-intro.html#the-cowplot-package",
    "title": "6  Introduction to ggplot2",
    "section": "6.22 The cowplot package",
    "text": "6.22 The cowplot package\nA common task when preparing visualizations for scientific presentations and manuscripts is combining different plots as subfigures of a larger figure. To accomplish this we’ll use a package called cowplot that compliments the power of ggplot2. Install cowplot either via the command line or the R Studio GUI (see Section @ref(packages)).\n\nlibrary(cowplot) # assumes package has been installed\n\ncowplot allows us to create individual plots using ggplot, and then arrange them in a grid-like fashion with labels for each plot of interest, as you would typically see in publications. The core function of cowplot is plot_grid(), which allows the user to layout the sub-plots in an organized fashion and add labels as necesary.\nTo illustrate plot_grid() let’s create three different representations of the distribution of sepal width in the irisu data set, and combine them into a single figure:\n\np <- ggplot(iris, \n            mapping = aes(x = Species, y = Sepal.Width, color = Species))\n\n# for the histogram we're going to override the mapping because\n# geom_histogram only takes an x argument\nplot.1 <- p + \n  geom_histogram(bins=12,\n                 mapping = aes(x = Sepal.Width), inherit.aes = FALSE)\nplot.2 <- p + geom_boxplot() \nplot.3 <- p + geom_violin()\n\nplot_grid(plot.1, plot.2, plot.3)\n\n\n\n\nIf instead, we wanted to layout the plots in a single row we could change the call to plot_grid as so:\n\nplot_grid(plot.1, plot.2, plot.3, \n          nrow = 1, labels = c(\"A\", \"B\", \"C\"))\n\n\n\n\nNotice we also added labels to our sub-plots."
  },
  {
    "objectID": "Python/Python-getting-acquainted.html",
    "href": "Python/Python-getting-acquainted.html",
    "title": "7  About Python",
    "section": "",
    "text": "Python is a programming language invented in the early 1980’s by a Dutch programmer named Guido van Rossum who was working at the Dutch National Research Institute for Mathematics and Computer Science. Python is a high-level programming language with a simple syntax that is easy to learn. The language supports a variety of programming paradigms including procedural programming, object-oriented programming, as well as some functional programming idioms. The name of the language is a whimsical nod toward Monty Python’s Flying Circus.\nPython has a very active development community. There is a stable core to the language, but new language features are also being developed. Python has an extensive standard library that includes facilities for a wide range of programming tasks. There is a very large user community the provides support and helps to develop an extensive set of third-party libraries. Python is also highly portable – it is available on pretty much any computing platform you’re likely to use. Python is also open-source and free!\n\n8 Python Resources\nThere are many resources available online and in bookstores for learning Python. A few handy resources are listed here:\n\nPython Website – the official website for the programming language.\nThe Python Tutorial – the ‘official’ Python tutorial.\nPython Library Reference – a reference guide to the many modules that come included with Python.\nThink Python: How to Think Like a Computer Scientist – a free book that provides an introduction to programming using Python.\n\n\n\n9 Starting the Python interpreter\nThe Python interpreter can be started in a number of ways. The simplest way is to open a shell (terminal) and type python. You can open a terminal as follows:\n\nOn a Mac (OS X) run the terminal program available under Applications > Utilities\nOn Windows open up a command prompt, available from Start Menu > Accessories.\n\nOnce you’re at the command prompt type the following command:\npython\nIf everything is working correctly you should see something like:\nPython 3.10.4 | packaged by conda-forge | (main, Mar 24 2022, 17:42:03) [Clang 12.0.1 ] on darwin\nType \"help\", \"copyright\", \"credits\" or \"license\" for more information.\n>>> \nIf that command didn’t work, please see me for further help configuring your Python installation. From within the default interpretter you can type Ctrl-d (Unix, MacOS) , Ctrl-z (Windows) or type quit() to stop the interpreter and return to the command line."
  },
  {
    "objectID": "Unix/Unix-bash.html#writing-shell-scripts",
    "href": "Unix/Unix-bash.html#writing-shell-scripts",
    "title": "8  Bash scripts",
    "section": "8.1 Writing shell scripts",
    "text": "8.1 Writing shell scripts\nShell scripts are small programs written in the language of the shell; they’re convenient for tying together a series of commands that you might otherwise type by hand into a repeatable and documented set of operations. Bash scripts also allow us to write new commands or programs that can be used in a manner similar to other “built-in” programs we’ve been using."
  },
  {
    "objectID": "Unix/Unix-bash.html#bash-scripts-are-picky",
    "href": "Unix/Unix-bash.html#bash-scripts-are-picky",
    "title": "8  Bash scripts",
    "section": "8.2 Bash scripts are picky",
    "text": "8.2 Bash scripts are picky\nOne annoying feature of bash scripting is that it’s particularly picky about white space around commands and arguments, because essentially it tries to execute each line as if it was written at the command line itself (see). When following the examples below I recommend you be careful to follow the spacing I’ve used to avoid hard to diagnose syntax errors. For this reason, bash is not my preferred scripting environment. However it’s so ubiquitous in bioinformatics that it’s worth learning the basics of bash."
  },
  {
    "objectID": "Unix/Unix-bash.html#simple-script-examples",
    "href": "Unix/Unix-bash.html#simple-script-examples",
    "title": "8  Bash scripts",
    "section": "8.3 Simple script examples",
    "text": "8.3 Simple script examples\n\n8.3.1 Simple shell script 01\nLet’s start with the simplest possible shell script – one that simply writes a message to stdout.\nPut the following code into a file named tut01.sh:\n# tut01.sh\necho \"Hello, shell world!\"\nNow you can call your shell script as so from the command line (assuming it’s in your current working directory)\nbash tut01.sh\nThis one line script simply called the echo command line tool to write text to stdout.\n\n\n8.3.2 Simple shell script 02\nThat’s a pretty boring shell script. Let’s create a new version that takes as input an argument telling it what to print after the initial greeting. $1 is how we designate the first argument from the command line.\n# tut02.sh\necho \"Hello, $1\"\nThis expects an argument from the command line, so run this script as follows, substituting Paul as appropriate:\nbash tut02.sh Paul\n\n\n8.3.3 Simple shell script 03\nShell scripts can create variables to hold the output of commands. This is illustrated below in which we create a variable input_reversed to hold the value of a computation done on the first argument to the script:\n# tut03.sh\n# note that rev command reverses lines of input\ninput_reversed=$(echo $1 | rev) \necho \"$1 reversed is $input_reversed\"\nAnd we again run it as:\nbash tut03.sh \"Twas brillig and the slithey toves...\"\nNotice that I wrapped the text in quotes. What happens if you don’t include the quotes?\n\n\n8.3.4 Simple shell script 04\nWe can get multiple arguments from the command line:\n# tut04.sh\necho \"The first argument was: $1\"\necho \"The second argument was: $2\"\nOr we can check the number of arguments:\n# tut04a.sh\nnargs=$#\n\nif [[ $nargs -ne 2 ]]\nthen\n    echo \"I need two arguments!\"\n    exit\nfi\n\necho \"The first argument was: $1\"\necho \"The second argument was: $2\""
  },
  {
    "objectID": "Unix/Unix-bash.html#different-ways-of-using-bash-scripts",
    "href": "Unix/Unix-bash.html#different-ways-of-using-bash-scripts",
    "title": "8  Bash scripts",
    "section": "8.4 Different ways of using Bash scripts",
    "text": "8.4 Different ways of using Bash scripts\n\n8.4.1 Reproducibility\n\nDid your analysis require a bunch of different steps? Could you reproduce what you did? Could you teach someone else to do it?\nPut each of the steps of your analysis into a bash script and save the file with a .sh ending. You or someone else can replicate your analysis by running bash yourscriptname.sh. Consider saving all such scripts you create for reproducibility purposes to a git repository.\n\nExample:\n# yeast_feature_counts.sh\n#\n# Purpose: count feature types in yeast genome annotation GFF file\n# Output: a CSV table sorted by freq of feature\n\nwget -q https://ftp.ncbi.nlm.nih.gov/genomes/refseq/fungi/Saccharomyces_cerevisiae/reference/GCF_000146045.2_R64/GCF_000146045.2_R64_genomic.gff.gz\n\ngunzip GCF_000146045.2_R64_genomic.gff.gz\n\nawk -F\"\\t\" -v OFS=\",\" \\\n    'NF == 9 {cts[$3] += 1}\n    END {for (ftr in cts) \n            print ftr, cts[ftr] }' \\\n    GCF_000146045.2_R64_genomic.gff |\nsort -t, -k 2 -nr \nYou can execute this script by calling it as an argument to bash:\nbash yeast_feature_counts.sh > yeast_features.csv\n\n\n8.4.2 Reusability\n\nYou developed a pipeline to solve one instance of a problem. Is this a type of computation you do repeatedly or are likely to do in the future on different inputs?\nCreate a bash script “template” by re-writing the script to include variables for specifying input and output file name, key parameters, etc.\n\n# feature_count_template.sh\n#\n# Purpose: count feature types in any GFF annotation\n# output a CSV table sorted by freq of feature\n\n# --- REPLACE THESE VARIABLES --- #\n\nGFF_URL=\"\"  # RefSeq URL Location\nOUT_DIR=\"output\"  # Directory for output, will be created if necessary\n\n# -- END USER DEFINED VARIBLES -- #\n\n# Create output directory if it doesn't exist\nif [ ! -e ${OUT_DIR} ]; then\n    mkdir -p ${OUT_DIR}\nfi\n\n# intermediate files written to OUT_DIR\ngff_gz=${OUT_DIR}/gff.gz\ngff_file=${OUT_DIR}/features.gff\n\n# download and unzip the data if \nif [ ! -f ${gff_file} ]; then\n    wget ${GFF_URL} -O ${gff_gz}\n    gunzip ${gff_gz} -c > ${gff_file} \nfi\n\n# run the analysis sending the results to stdout\nawk -F\"\\t\" -v OFS=\",\" \\\n    'NF == 9 {cts[$3] += 1}\n    END {for (ftr in cts) \n            print ftr, cts[ftr] }' \\\n    ${gff_file}  |\nsort -t, -k 2 -nr \nIf you, or someone you gave the script to, wanted to use this to run the analysis on another organism you would make a copy:\ncp feature_count_template.sh ecoli_feature_count.sh\nmodify the GFF_URL and OUT_DIR lines appropriately:\n# ecoli_feature_count.sh\n#\n# Purpose: count feature types in E coli genome\n# Output: a CSV table sorted by freq of feature\n\nGFF_URL=\"https://ftp.ncbi.nlm.nih.gov/genomes/refseq/bacteria/Escherichia_coli/reference/GCF_000005845.2_ASM584v2/GCF_000005845.2_ASM584v2_genomic.gff.gz\"  \n\nOUT_DIR=\"Escherichia_coli\"\n\n... <rest of template stays the same...>\nand then run the script:\nbash ecoli_feature_count.sh\n\n\n8.4.3 Encapsulation and Abstraction\n\nYou developed a pipeline that carries out a useful computation that you want to integrate into other analyses or pipelines\nUse a bash script to turn your pipeline into a command that can be integrated into other pipelines, following the Unix philosophy. From the user’s perspective, you can think of this as “abstracting away” the details of how the analysis works. They no longer have to understand the details of how the program or command works, they simply have to know what data to call it with and the form of the output.\nHere we achieve this in a very simple way – by providing a way for our script to process arguments provided at the command line.\n#!/usr/bin/env bash\n# feature_count.sh -- download a GFF file from RefSeq and \n#   count the feature types\n\nnargs=$#\n\nif [ $nargs -ne 2 ]; then\n    echo \"usage: $0 URL OUTDIR\"\n    exit 1\nfi\n\nGFF_URL=$1  # RefSeq URL Location\nOUT_DIR=$2  # Directory for output, will be created if necessary\n\n# Create output directory if it doesn't exist\nif [ ! -e ${OUT_DIR} ]; then\n    mkdir -p ${OUT_DIR}\nfi\n\n# intermediate files written to OUT_DIR\ngff_gz=${OUT_DIR}/gff.gz\ngff_file=${OUT_DIR}/features.gff\n\n# download and unzip the data if \nif [ ! -f ${gff_file} ]; then\n    wget ${GFF_URL} -O ${gff_gz}\n    gunzip ${gff_gz} -c > ${gff_file} \nfi\n\n# run the analysis sending the results to stdout\nawk -F\"\\t\" -v OFS=\",\" \\\n    'NF == 9 {cts[$3] += 1}\n    END {for (ftr in cts) \n            print ftr, cts[ftr] }' \\\n    ${gff_file}  |\nsort -t, -k 2 -nr \n\nMake this script executable (chmod +x feature_count.sh). You can call it directly from your working directory or add it to your PATH. Having done this you can use this script by specifying a URL and a directory name to write the output files to. Since the URL is long I assign it to a variable:\ncelegans_url=https://ftp.ncbi.nlm.nih.gov/genomes/refseq/invertebrate/Caenorhabditis_elegans/reference/GCF_000002985.6_WBcel235/GCF_000002985.6_WBcel235_genomic.gff.gz\nAnd then call the bash script\nfeature_count.sh $celegans_url celegans\n\n8.4.3.1 Back to reproducibility\nBy encapsulating our pipeline we’ve made it reusable and generalizable to analyses of arbitrary GFF annotation files. However, we’ve lost an element of reproducibility because we’re no longer documenting the data sources used when we invoke it at the command line. Luckily it’s easy to restore that with – you guessed it – another bash script!\nTo illustrate this, let’s assume we wanted to compare feature counts across multiple genomes. Let’s put species names and corresponding RefSeq URLs in a CSV file called genomelist.csv:\nSaccharomyces_cerevisiae,https://ftp.ncbi.nlm.nih.gov/genomes/refseq/fungi/Saccharomyces_cerevisiae/reference/GCF_000146045.2_R64/GCF_000146045.2_R64_genomic.gff.gz\nEscherichia_coli,https://ftp.ncbi.nlm.nih.gov/genomes/refseq/bacteria/Escherichia_coli/reference/GCF_000005845.2_ASM584v2/GCF_000005845.2_ASM584v2_genomic.gff.gz\nCaenorhabditis_elegans,https://ftp.ncbi.nlm.nih.gov/genomes/refseq/invertebrate/Caenorhabditis_elegans/reference/GCF_000002985.6_WBcel235/GCF_000002985.6_WBcel235_genomic.gff.gz\nNow we can generate feature counts for each genome by creating a bash script called multi_species_count.sh that includes a call to parallel:\n# multi_species_count.sh\n\nparallel --colsep=\",\" 'mkdir -p {1}; ./feature_count.sh {2} {1} > {1}/ftrcounts.csv' :::: genomelist.csv\nand run this as:\nbash multi_species_count.sh\nFor each species name in your input list, there should now be a corresponding directory that contains a ftrcounts.csv file with the respective counts:\n$ ls -1 */ftrcounts.csv\nCaenorhabditis_elegans/ftrcounts.csv\nEscherichia_coli/ftrcounts.csv\nSaccharomyces_cerevisiae/ftrcounts.csv\nIn terms of reproducibility, our full analysis now requires three files:\n\nThe feature_count.sh script\nThe list of genomes we’re processing: genomelist.csv\nOur multi_species_count.sh that processes the information in (2) through the pipeline in (1)\n\nThere is a slight increase in complexity versus our single species script, but with the following advantages:\n\nIt’s trivial to extend our analysis to include new species/genomes of interest – we simply add additional species names and URLs to genomelist.csv\nWe can run this analysis efficiently for many genomes at once by adding the argument --jobs=n to the call to parallel where n is the number of threads we want to run simultaneously (assuming that you have access to a multi-CPU machine or a compute cluster)"
  },
  {
    "objectID": "Unix/Unix-bash.html#other-resources",
    "href": "Unix/Unix-bash.html#other-resources",
    "title": "8  Bash scripts",
    "section": "8.5 Other resources",
    "text": "8.5 Other resources\nThe above is a short intro to bash scripting. Some other useful resources include:\n\nhttps://linuxconfig.org/bash-scripting-tutorial-for-beginners – provides a good overview of bash\nhttps://www.shellscript.sh/ – an in-depth tutorial on bash scripting"
  },
  {
    "objectID": "Unix/Unix-awk.html#simple-examples",
    "href": "Unix/Unix-awk.html#simple-examples",
    "title": "9  Awk",
    "section": "9.1 Simple examples",
    "text": "9.1 Simple examples\nOne simple thing we can do with Awk is to use it to re-order fields in a structured data file:\nawk '{print $2, $1, $3}' columns.txt\nThe text in quotes represents the Awk program which we’re apply to the file columns.txt. The dollar signs followed by numbers refer to the fields of the file. With it’s default setting awk operates line by line, so you can interpret the above statement as saying:\n\n“for each line, print the fields 2, 1, and 3”."
  },
  {
    "objectID": "Unix/Unix-awk.html#awk-delimiters",
    "href": "Unix/Unix-awk.html#awk-delimiters",
    "title": "9  Awk",
    "section": "9.2 Awk delimiters",
    "text": "9.2 Awk delimiters\nBy default, Awk recognizes any non printing character including spaces to delineate fields/columns. If we want to be specific about the character used as a delimiter, we can set the -F or --field-separator option. For example to use tabs as the delimiter we could do:\nawk -F'\\t' '{print $2, $1, $3}' columns.txt"
  },
  {
    "objectID": "Unix/Unix-awk.html#pattern-action-syntax",
    "href": "Unix/Unix-awk.html#pattern-action-syntax",
    "title": "9  Awk",
    "section": "9.3 pattern {action} syntax",
    "text": "9.3 pattern {action} syntax\nThe basic syntax of awk is often depicted in the form pattern {action}. The above command only specified an action, so it was applied to every line. By contrast, in the example below we specify both a pattern and an action. The pattern can be read as – “if the 2nd field is ‘chromosome’”. For all lines that match that pattern the corresponding action is applied; in this case the action is “print fields 1 and 4” (the chromosome name and its length):\nawk '$2==\"chromosome\" {print $1, $4}' yeast_features.txt\nHere’s another pattern {action} pair that shows how we could find all gene features with length less than 300 and count them:\nawk '$2 == \"gene\" && ($4 - $3 + 1) < 300 {print $0 }' yeast_features.txt | wc -l\n&& is the AND operator. Read this as “if the 2nd field is ‘gene’ AND the length of the feature is less than 300.” (Note: we add one to the calculation of length because the feature coordinates are inclusive of both the start and end coordinate).\nIn this last example we add one more condition – we use a regular expression against the 6th field ($6 ~ /../) to look for the string “orf_classification=Dubious”. The results indicate that about a third of these small gene features have been classified as “dubious” (i.e. may not actually code for proteins).\nawk '$2 == \"gene\" && ($4 - $3 + 1) < 300 && $6 ~ /orf_classification=Dubious/ {print $0 }' yeast_features.txt | wc -l"
  },
  {
    "objectID": "Unix/Unix-awk.html#multiple-rules-and-awk-scripts",
    "href": "Unix/Unix-awk.html#multiple-rules-and-awk-scripts",
    "title": "9  Awk",
    "section": "9.4 Multiple rules and Awk scripts",
    "text": "9.4 Multiple rules and Awk scripts\nSo far our pattern {action} rules have matched focused on single patterns. However, you can specify multiple matching rules and do different computations depending on which one matches. For example, if we wanted to count genes and mRNAs simultaneously in an annotation file and then print out the counts at the end, we can construct a awk call with three rules:\nawk '$2 == \"gene\" {gene_ct += 1} $2 == \"mRNA\" {mRNA_ct += 1} END {print gene_ct, mRNA_ct}' yeast_features.txt\nAt this point the command line is getting a little out of control so it would be better to put the rules into a file we can call. In your editor create a file called count_genes_mRNAs.awk with the following contents:\n$2 == \"gene\" {\n    gene_ct += 1\n} \n\n$2 == \"mRNA\" {\n    mRNA_ct += 1\n} \n\n## called once all lines have been processed\nEND {\n    print gene_ct, mRNA_ct\n}\nThis file works exactly like our command line version, but it has the advantages that it’s easier to read and thus easier to debug or modify. To call this Awk program from the command line we use the -f option to specify the script:\nawk -f count-genes-mRNAs.awk yeast_features.txt"
  },
  {
    "objectID": "Unix/Unix-awk.html#variables-in-awk",
    "href": "Unix/Unix-awk.html#variables-in-awk",
    "title": "9  Awk",
    "section": "9.5 Variables in Awk",
    "text": "9.5 Variables in Awk\nThe prior example introduced the use of “variables” in Awk. Variables store values; in Awk that are only two variable types, strings and numbers.\n\n9.5.1 Numerical variables\nIn the example above gene_ct and mRNA_ct are numerical variables. In Awk, when a numerical value is first created (initialized) it’s automatically assigned the value zero. In this example we used these variables in lines that look like gene_ct += 1; the += operator is a short-hand way of saying “add the value on the right to the value of the variable on the left” so this statement is equivalent to the slightly wordier gene_ct = gene_ct + 1.\n\n\n9.5.2 String variables\nString variables are created by wrapping characters in double quotes.\nawk 'BEGIN {a = \"Hello\"; b = \"World\"; print a b}'\nYou can get the length of a string using the length() function:\nawk 'BEGIN {a = \"Hello\"; print \"The length of \" a \" is \" length(a)}'\nThe GNU Awk implementation (gawk) provides a wide variety of string functions. Some of the most useful include: substr(), split(), and gsub()/sub() . Here’s an example using substr():\nawk '\nBEGIN {\n  s = \"Jabberwocky\"\n  print substr(s, 4, 7) # arguments are string, start, length\n}'"
  },
  {
    "objectID": "Unix/Unix-awk.html#arrays-in-awk",
    "href": "Unix/Unix-awk.html#arrays-in-awk",
    "title": "9  Awk",
    "section": "9.6 Arrays in Awk",
    "text": "9.6 Arrays in Awk\nMost programming languages have a core set of “data structures” which specify different ways of storing and accessing values. In Awk the core data structure is called an array. It has some superficial similarities to arrays (sometimes called lists) in other languages, but also has some features that are fairly unique to Awk.\nAn array can be thought of being made up of a contiguous set of slots or positions where we can store values. Each slot has an associated label that we call its index (plural indices). In most languages array indices are integers, with the first position indexed by successive integer values (some languages start indexing the 0, others with 1). In Awk, array indices can be either numbers or strings. This makes arrays in Awk a little like a combination between what other languages might call an array (or list) and a dictionary (hash map).\nHere are some illustrations of using arrays in Awk:\n\nThe split() function splits a string based on a delimiter and returns the substrings in an array that is indexed by integer position\nawk '\nBEGIN {\n  name = \"kebab-case-name\"\n  split(name, parts, \"-\")  # parts array is created\n  print \"part 1: \" parts[1]\n  print \"part 2: \" parts[2]\n  print \"part 3: \" parts[3]\n}'\nTypically you’d use a for-loop to iterate over the indices of parts\nawk '\nBEGIN {\n  name = \"kebab-case-name\"\n  # split() return the number of substrings it creates\n  n = split(name, parts, \"-\") \n\n  # for-loop iterating over integer indices\n  for (i = 1; i <= n; ++i )\n    print \"part \" i \": \" parts[i]\n}'\nuniqct.awk – a program that outputs a table listing the unique set of lines in the input, and the number of times that each line appears\n# this rule applies to every line, $0 returns the whole line\n{ counts[$0] += 1 }\n\nEND{\n  # for loop with implicit indices\n  for (idx in counts)   \n    print idx, counts[idx]\n}\nThis code might be used like so:\ncut -f 2 yeast_features.txt | awk -f uniqct.awk\n\nFor a full exposition on Awk’s arrays, read the Gawk manual on the Basics of Arrays. Here I illustrate some basic uses of arrays."
  },
  {
    "objectID": "Unix/Unix-awk.html#some-useful-awk-constructs",
    "href": "Unix/Unix-awk.html#some-useful-awk-constructs",
    "title": "9  Awk",
    "section": "9.7 Some useful Awk constructs",
    "text": "9.7 Some useful Awk constructs\n\nBEGIN {action} – do the specified action before reading any input\nEND {action} – do the specified action after reading all input\nnext – the next statement causes Awk to stop processing the current record (line) and move onto the next record.\nexit – the exit statement immediately stops execution of any rules and jumps to the END rule. Useful for terminating processing based on a condition.\nRecord and field counts:\n\nFNR and NR – FNR gives the current record number in the current file (awk can process multiple files simultaneously); NR gives the total number of records seen so far. When processing a single file, FNR == NR\nNF – gives the number of fields in the current record(line)\nawk -F \"\\t\" `{print \"There are\", NF, \"fields in line\", FNR}` yeast_features.txt \n\nField separators – both the input field separator (FS) and the output field separator (OFS) can be specified in an Awk program. This is usually done in a BEGIN rule:\n\nfirstlast_csv.awk – outputs first and last fields of input file in CSV separated fields\nBEGIN {\n  OFS = \",\"\n}\n\n{print $1, $NF} # applies to every line\n\nMatching and extracting information using regular expressions\n\nmatch(field, regex) – this function find the specified regex in the given field. Per the gawk manual: “Returns the character position (index) at which that substring begins (one, if it starts at the beginning of string). If no match is found, return zero.”\nThe following example returns all features in a GFF file for which the attribute field (column 9) includes an ID designation.\nawk 'match($9, \"ID=([^;]+)\") {print $0}' yeast.gff\ngawk provides a more powerful version of match where the matches can take an optional array as the third argument. As described in the Gawk manual:\n\nIf array is present, it is cleared, and then the zeroth element of array is set to the entire portion of string matched by regexp. If regexp contains parentheses, the integer-indexed elements of array are set to contain the portion of string matching the corresponding parenthesized subexpression.\n\nHere’s an example of using the gawk match function to extract the ID attribute for every gene feature and create a new table giving ID, landmark, and start and end coordinates.\n$3 == \"gene\" {\n    id = \"\"\n    if (match($9, \"ID=([^;]+);\", matchvar))\n        id = matchvar[1]\n    print id, $1, $4, $5\n}\nIf we put this in idgenes.awk we can call it as:\nawk -f idgenes.awk yeast.gff"
  }
]